<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Mini Challenge: Gradient Descent</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="vta_mc_1_files/libs/clipboard/clipboard.min.js"></script>
<script src="vta_mc_1_files/libs/quarto-html/quarto.js"></script>
<script src="vta_mc_1_files/libs/quarto-html/popper.min.js"></script>
<script src="vta_mc_1_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="vta_mc_1_files/libs/quarto-html/anchor.min.js"></script>
<link href="vta_mc_1_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="vta_mc_1_files/libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="vta_mc_1_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="vta_mc_1_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="vta_mc_1_files/libs/bootstrap/bootstrap-a1ff8711b79ae3724c050874b28d9907.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#einleitung" id="toc-einleitung" class="nav-link active" data-scroll-target="#einleitung">Einleitung</a></li>
  <li><a href="#inhalt" id="toc-inhalt" class="nav-link" data-scroll-target="#inhalt">Inhalt</a>
  <ul class="collapse">
  <li><a href="#aufgabe-1-datenimport-und-exploration" id="toc-aufgabe-1-datenimport-und-exploration" class="nav-link" data-scroll-target="#aufgabe-1-datenimport-und-exploration">Aufgabe 1 – Datenimport und Exploration</a></li>
  <li><a href="#aufgabe-2-implementierung-eines-linearen-layers-in-numpy" id="toc-aufgabe-2-implementierung-eines-linearen-layers-in-numpy" class="nav-link" data-scroll-target="#aufgabe-2-implementierung-eines-linearen-layers-in-numpy">Aufgabe 2 – Implementierung eines linearen Layers in NumPy</a></li>
  <li><a href="#aufgabe-3-einfaches-neuronales-netz-binary-classification" id="toc-aufgabe-3-einfaches-neuronales-netz-binary-classification" class="nav-link" data-scroll-target="#aufgabe-3-einfaches-neuronales-netz-binary-classification">Aufgabe 3 – Einfaches neuronales Netz (Binary Classification)</a></li>
  <li><a href="#aufgabe-4-hyperparameter-tuning-und-trainingsevaluation" id="toc-aufgabe-4-hyperparameter-tuning-und-trainingsevaluation" class="nav-link" data-scroll-target="#aufgabe-4-hyperparameter-tuning-und-trainingsevaluation">Aufgabe 4 – Hyperparameter-Tuning und Trainingsevaluation</a></li>
  <li><a href="#aufgabe-5-erweiterung-zum-mehrklassen-klassifikator" id="toc-aufgabe-5-erweiterung-zum-mehrklassen-klassifikator" class="nav-link" data-scroll-target="#aufgabe-5-erweiterung-zum-mehrklassen-klassifikator">Aufgabe 5 – Erweiterung zum Mehrklassen-Klassifikator</a></li>
  <li><a href="#anhang" id="toc-anhang" class="nav-link" data-scroll-target="#anhang">Anhang</a></li>
  </ul></li>
  <li><a href="#aufgabe-1-laden-und-erkunden-des-mnist-datensatzes" id="toc-aufgabe-1-laden-und-erkunden-des-mnist-datensatzes" class="nav-link" data-scroll-target="#aufgabe-1-laden-und-erkunden-des-mnist-datensatzes">Aufgabe 1 – Laden und Erkunden des MNIST-Datensatzes</a>
  <ul class="collapse">
  <li><a href="#import-von-libraries" id="toc-import-von-libraries" class="nav-link" data-scroll-target="#import-von-libraries">Import von Libraries</a></li>
  <li><a href="#verwendung-von-torchvision-zum-laden-der-daten" id="toc-verwendung-von-torchvision-zum-laden-der-daten" class="nav-link" data-scroll-target="#verwendung-von-torchvision-zum-laden-der-daten">Verwendung von torchvision zum Laden der Daten</a></li>
  <li><a href="#überblick-über-struktur-verteilung-und-eigenschaften-des-datensatzes" id="toc-überblick-über-struktur-verteilung-und-eigenschaften-des-datensatzes" class="nav-link" data-scroll-target="#überblick-über-struktur-verteilung-und-eigenschaften-des-datensatzes">Überblick über Struktur, Verteilung und Eigenschaften des Datensatzes</a></li>
  <li><a href="#visualisierung-erster-beispiele" id="toc-visualisierung-erster-beispiele" class="nav-link" data-scroll-target="#visualisierung-erster-beispiele">Visualisierung erster Beispiele</a></li>
  </ul></li>
  <li><a href="#aufgabe-2-implementierung-eines-linearen-layers-in-numpy-1" id="toc-aufgabe-2-implementierung-eines-linearen-layers-in-numpy-1" class="nav-link" data-scroll-target="#aufgabe-2-implementierung-eines-linearen-layers-in-numpy-1">Aufgabe 2 – Implementierung eines linearen Layers in NumPy</a>
  <ul class="collapse">
  <li><a href="#klasse-linearlayer-forward-backward-und-update" id="toc-klasse-linearlayer-forward-backward-und-update" class="nav-link" data-scroll-target="#klasse-linearlayer-forward-backward-und-update">Klasse <code>LinearLayer</code>: Forward, Backward und Update</a></li>
  <li><a href="#unittest-für-linearlayer" id="toc-unittest-für-linearlayer" class="nav-link" data-scroll-target="#unittest-für-linearlayer">Unittest für LinearLayer</a></li>
  </ul></li>
  <li><a href="#aufgabe-3-einfaches-neuronales-netzwerk-zur-klassifikation-einer-ziffer" id="toc-aufgabe-3-einfaches-neuronales-netzwerk-zur-klassifikation-einer-ziffer" class="nav-link" data-scroll-target="#aufgabe-3-einfaches-neuronales-netzwerk-zur-klassifikation-einer-ziffer">Aufgabe 3 – Einfaches neuronales Netzwerk zur Klassifikation einer Ziffer</a>
  <ul class="collapse">
  <li><a href="#datenumwandlung-torch-dataset-nach-numpy-binäre-zielvariable" id="toc-datenumwandlung-torch-dataset-nach-numpy-binäre-zielvariable" class="nav-link" data-scroll-target="#datenumwandlung-torch-dataset-nach-numpy-binäre-zielvariable">Datenumwandlung: Torch-Dataset nach NumPy + binäre Zielvariable</a></li>
  <li><a href="#aktivierungsfunktionen-relu-und-sigmoid" id="toc-aktivierungsfunktionen-relu-und-sigmoid" class="nav-link" data-scroll-target="#aktivierungsfunktionen-relu-und-sigmoid">Aktivierungsfunktionen: ReLU und Sigmoid</a></li>
  <li><a href="#verlustfunktion-binary-cross-entropy-mit-gewichtung" id="toc-verlustfunktion-binary-cross-entropy-mit-gewichtung" class="nav-link" data-scroll-target="#verlustfunktion-binary-cross-entropy-mit-gewichtung">Verlustfunktion: Binary Cross Entropy (mit Gewichtung)</a></li>
  <li><a href="#accuracy-als-evaluationsmetrik-für-binäre-klassifikation" id="toc-accuracy-als-evaluationsmetrik-für-binäre-klassifikation" class="nav-link" data-scroll-target="#accuracy-als-evaluationsmetrik-für-binäre-klassifikation">Accuracy als Evaluationsmetrik für binäre Klassifikation</a></li>
  <li><a href="#netzwerkarchitektur-klasse-simplenn" id="toc-netzwerkarchitektur-klasse-simplenn" class="nav-link" data-scroll-target="#netzwerkarchitektur-klasse-simplenn">Netzwerkarchitektur: Klasse <code>SimpleNN</code></a></li>
  <li><a href="#trainingsloop-mit-vollständigem-batch-training" id="toc-trainingsloop-mit-vollständigem-batch-training" class="nav-link" data-scroll-target="#trainingsloop-mit-vollständigem-batch-training">Trainingsloop mit vollständigem Batch-Training</a></li>
  <li><a href="#visualisierung-des-trainingsverlaufs-referenzmodell" id="toc-visualisierung-des-trainingsverlaufs-referenzmodell" class="nav-link" data-scroll-target="#visualisierung-des-trainingsverlaufs-referenzmodell">Visualisierung des Trainingsverlaufs (Referenzmodell)</a></li>
  <li><a href="#mathematischer-hintergrund" id="toc-mathematischer-hintergrund" class="nav-link" data-scroll-target="#mathematischer-hintergrund">Mathematischer Hintergrund</a></li>
  </ul></li>
  <li><a href="#aufgabe-4-training-mit-variierenden-hyperparametern" id="toc-aufgabe-4-training-mit-variierenden-hyperparametern" class="nav-link" data-scroll-target="#aufgabe-4-training-mit-variierenden-hyperparametern">Aufgabe 4 – Training mit variierenden Hyperparametern</a>
  <ul class="collapse">
  <li><a href="#netzwerkkonfiguration-für-die-experimente" id="toc-netzwerkkonfiguration-für-die-experimente" class="nav-link" data-scroll-target="#netzwerkkonfiguration-für-die-experimente">Netzwerkkonfiguration für die Experimente</a></li>
  <li><a href="#referenzdurchlauf-mit-festen-hyperparametern" id="toc-referenzdurchlauf-mit-festen-hyperparametern" class="nav-link" data-scroll-target="#referenzdurchlauf-mit-festen-hyperparametern">Referenzdurchlauf mit festen Hyperparametern</a></li>
  <li><a href="#diskussion-des-trainingsverlaufs" id="toc-diskussion-des-trainingsverlaufs" class="nav-link" data-scroll-target="#diskussion-des-trainingsverlaufs">Diskussion des Trainingsverlaufs</a></li>
  <li><a href="#vergleich-verschiedener-lernraten-und-hidden-grössen" id="toc-vergleich-verschiedener-lernraten-und-hidden-grössen" class="nav-link" data-scroll-target="#vergleich-verschiedener-lernraten-und-hidden-grössen">Vergleich verschiedener Lernraten und Hidden-Grössen</a></li>
  <li><a href="#diskussion-der-hyperparameter-experimente" id="toc-diskussion-der-hyperparameter-experimente" class="nav-link" data-scroll-target="#diskussion-der-hyperparameter-experimente">Diskussion der Hyperparameter-Experimente</a></li>
  </ul></li>
  <li><a href="#aufgabe-5-erweiterung-zum-mehrklassen-klassifikator-1" id="toc-aufgabe-5-erweiterung-zum-mehrklassen-klassifikator-1" class="nav-link" data-scroll-target="#aufgabe-5-erweiterung-zum-mehrklassen-klassifikator-1">Aufgabe 5 – Erweiterung zum Mehrklassen-Klassifikator</a>
  <ul class="collapse">
  <li><a href="#ziele-der-aufgabe" id="toc-ziele-der-aufgabe" class="nav-link" data-scroll-target="#ziele-der-aufgabe">Ziele der Aufgabe:</a></li>
  <li><a href="#softmax-aktivierungsfunktion" id="toc-softmax-aktivierungsfunktion" class="nav-link" data-scroll-target="#softmax-aktivierungsfunktion">Softmax-Aktivierungsfunktion</a></li>
  <li><a href="#cross-entropy-verlustfunktion-für-mehrklassenklassifikation" id="toc-cross-entropy-verlustfunktion-für-mehrklassenklassifikation" class="nav-link" data-scroll-target="#cross-entropy-verlustfunktion-für-mehrklassenklassifikation">Cross-Entropy-Verlustfunktion für Mehrklassenklassifikation</a></li>
  <li><a href="#evaluationsmetrik-klassifikationsgenauigkeit-accuracy" id="toc-evaluationsmetrik-klassifikationsgenauigkeit-accuracy" class="nav-link" data-scroll-target="#evaluationsmetrik-klassifikationsgenauigkeit-accuracy">Evaluationsmetrik: Klassifikationsgenauigkeit (Accuracy)</a></li>
  <li><a href="#one-hot-encoding-der-zielwerte" id="toc-one-hot-encoding-der-zielwerte" class="nav-link" data-scroll-target="#one-hot-encoding-der-zielwerte">One-Hot-Encoding der Zielwerte</a></li>
  <li><a href="#vorbereitung-der-trainings--und-testdaten-für-die-mehrklassenklassifikation" id="toc-vorbereitung-der-trainings--und-testdaten-für-die-mehrklassenklassifikation" class="nav-link" data-scroll-target="#vorbereitung-der-trainings--und-testdaten-für-die-mehrklassenklassifikation">Vorbereitung der Trainings- und Testdaten für die Mehrklassenklassifikation</a></li>
  <li><a href="#netzwerkarchitektur-multilayernn-mit-drei-gleich-grossen-hidden-layers" id="toc-netzwerkarchitektur-multilayernn-mit-drei-gleich-grossen-hidden-layers" class="nav-link" data-scroll-target="#netzwerkarchitektur-multilayernn-mit-drei-gleich-grossen-hidden-layers">Netzwerkarchitektur: <code>MultiLayerNN</code> mit drei gleich grossen Hidden Layers</a></li>
  <li><a href="#trainingsschleife-mit-mini-batch-verfahren" id="toc-trainingsschleife-mit-mini-batch-verfahren" class="nav-link" data-scroll-target="#trainingsschleife-mit-mini-batch-verfahren">Trainingsschleife mit Mini-Batch-Verfahren</a></li>
  <li><a href="#warum-mini-batch-training" id="toc-warum-mini-batch-training" class="nav-link" data-scroll-target="#warum-mini-batch-training">Warum Mini-Batch-Training?</a></li>
  <li><a href="#diskussion-der-hyperparameter-experimente-1" id="toc-diskussion-der-hyperparameter-experimente-1" class="nav-link" data-scroll-target="#diskussion-der-hyperparameter-experimente-1">Diskussion der Hyperparameter-Experimente</a></li>
  <li><a href="#training-des-finalen-modells-bestes-ergebnis-aus-grid-search" id="toc-training-des-finalen-modells-bestes-ergebnis-aus-grid-search" class="nav-link" data-scroll-target="#training-des-finalen-modells-bestes-ergebnis-aus-grid-search">Training des finalen Modells (Bestes Ergebnis aus Grid Search)</a></li>
  </ul></li>
  <li><a href="#zusatz-precision-recall-und-konfusionmatrix" id="toc-zusatz-precision-recall-und-konfusionmatrix" class="nav-link" data-scroll-target="#zusatz-precision-recall-und-konfusionmatrix">Zusatz: Precision, Recall und Konfusionmatrix</a>
  <ul class="collapse">
  <li><a href="#diskussion-der-ergebnisse" id="toc-diskussion-der-ergebnisse" class="nav-link" data-scroll-target="#diskussion-der-ergebnisse">Diskussion der Ergebnisse</a></li>
  </ul></li>
  <li><a href="#exkurs-klassifikation-mit-einem-convolutional-neural-network-cnn" id="toc-exkurs-klassifikation-mit-einem-convolutional-neural-network-cnn" class="nav-link" data-scroll-target="#exkurs-klassifikation-mit-einem-convolutional-neural-network-cnn">Exkurs: Klassifikation mit einem Convolutional Neural Network (CNN)</a>
  <ul class="collapse">
  <li><a href="#architektur" id="toc-architektur" class="nav-link" data-scroll-target="#architektur">Architektur:</a></li>
  <li><a href="#einordnung" id="toc-einordnung" class="nav-link" data-scroll-target="#einordnung">Einordnung:</a></li>
  <li><a href="#fazit-5" id="toc-fazit-5" class="nav-link" data-scroll-target="#fazit-5">Fazit:</a></li>
  </ul></li>
  <li><a href="#anhang-1" id="toc-anhang-1" class="nav-link" data-scroll-target="#anhang-1">Anhang</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Mini Challenge: Gradient Descent</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<ul>
<li>Authoren: Sandro <strong>Balz</strong>, Stefan <strong>Binkert</strong>, Christoph <strong>Elmiger</strong><br>
</li>
<li>Studiengang: FHNW Data Science BSc<br>
</li>
<li>Modul: Vertiefende Themen der Analysis<br>
</li>
<li>Fachexperte: Stefan Hackstein</li>
</ul>
<p><em>Zuletzt vollständig ausgeführt am 22.3.2025 in 2:03 Minuten</em></p>
<section id="einleitung" class="level2">
<h2 class="anchored" data-anchor-id="einleitung">Einleitung</h2>
<p>Dieses Jupyter Notebook wurde im Rahmen der Mini Challenge “Gradient Descent” aus der Veranstaltung Vertiefung Analysis erstellt. Ziel dieser Aufgabe ist es, ein grundlegendes Verständnis für numerische Näherungsverfahren in höheren Dimensionen zu entwickeln – insbesondere für den Gradient Descent und dessen Anwendung in neuronalen Netzwerken.</p>
<p>Anhand des MNIST-Datensatzes wird zunächst eine Datenexploration durchgeführt, anschliessend wird ein neuronales Netzwerk vollständig mit NumPy implementiert. Dabei werden alle wesentlichen Komponenten wie Forward- und Backward-Pass, Parameter-Updates sowie Trainings- und Evaluationsfunktionen selbst entwickelt. Abschliessend erfolgt eine Analyse des Trainingsverhaltens unter Variation der Lernrate und Netzwerkarchitektur.</p>
<p>Dieses Notebook dokumentiert nicht nur den Lösungsweg, sondern auch die wichtigsten Lernfortschritte, Herausforderungen und Erkenntnisse im Sinne eines Lerntagebuchs. Zur Unterstützung kamen auch KI-gestützte Tools wie ChatGPT zum Einsatz, deren Verwendung transparent offengelegt und reflektiert wird.</p>
</section>
<section id="inhalt" class="level2">
<h2 class="anchored" data-anchor-id="inhalt">Inhalt</h2>
<section id="aufgabe-1-datenimport-und-exploration" class="level3">
<h3 class="anchored" data-anchor-id="aufgabe-1-datenimport-und-exploration">Aufgabe 1 – Datenimport und Exploration</h3>
<ul>
<li>Laden des MNIST-Datensatzes mit torchvision</li>
<li>Analyse von Struktur, Format und Labelverteilung</li>
<li>Visuelle Exploration der Ziffern (Beispiele und Verteilungsgrafiken)</li>
</ul>
</section>
<section id="aufgabe-2-implementierung-eines-linearen-layers-in-numpy" class="level3">
<h3 class="anchored" data-anchor-id="aufgabe-2-implementierung-eines-linearen-layers-in-numpy">Aufgabe 2 – Implementierung eines linearen Layers in NumPy</h3>
<ul>
<li>Manuelle Implementierung eines vollvernetzten Layers (Forward, Backward, Update)</li>
<li>He-Initialisierung und Gradient Clipping</li>
<li>Verifikation durch explizite Unittests und händische Kontrollrechnung</li>
</ul>
</section>
<section id="aufgabe-3-einfaches-neuronales-netz-binary-classification" class="level3">
<h3 class="anchored" data-anchor-id="aufgabe-3-einfaches-neuronales-netz-binary-classification">Aufgabe 3 – Einfaches neuronales Netz (Binary Classification)</h3>
<ul>
<li>Konstruktion eines Netzwerks mit einem Hidden Layer</li>
<li>Klassifikation einer Zielziffer vs.&nbsp;Rest</li>
<li>Implementierung und mathematische Herleitung von Kosten- und Evaluationsfunktionen</li>
<li>Diskussion der Funktionswahl und möglicher Alternativen</li>
</ul>
</section>
<section id="aufgabe-4-hyperparameter-tuning-und-trainingsevaluation" class="level3">
<h3 class="anchored" data-anchor-id="aufgabe-4-hyperparameter-tuning-und-trainingsevaluation">Aufgabe 4 – Hyperparameter-Tuning und Trainingsevaluation</h3>
<ul>
<li>Systematische Variation von Lernrate und Hidden-Layer-Größe</li>
<li>Training über mehrere Epochen und Vergleich der Modelle</li>
<li>Darstellung und Interpretation von Trainings- und Testverläufen</li>
<li>Diskussion möglicher Trainingsprobleme und ihrer Ursachen</li>
</ul>
</section>
<section id="aufgabe-5-erweiterung-zum-mehrklassen-klassifikator" class="level3">
<h3 class="anchored" data-anchor-id="aufgabe-5-erweiterung-zum-mehrklassen-klassifikator">Aufgabe 5 – Erweiterung zum Mehrklassen-Klassifikator</h3>
<ul>
<li>Erweiterung auf ein Netzwerk mit 3 Hidden Layern und 10 Outputs</li>
<li>Training mit Mini-Batches</li>
<li>Wahl und Vergleich von Evaluations- und Kostenfunktionen für Multiklassen-Setups</li>
<li>Hyperparameteranalyse und Begründung der finalen Architektur</li>
</ul>
</section>
<section id="anhang" class="level3">
<h3 class="anchored" data-anchor-id="anhang">Anhang</h3>
<ul>
<li>Reflexion zur KI-Nutzung (inkl. Beispielchat)</li>
</ul>
</section>
</section>
<section id="aufgabe-1-laden-und-erkunden-des-mnist-datensatzes" class="level2">
<h2 class="anchored" data-anchor-id="aufgabe-1-laden-und-erkunden-des-mnist-datensatzes">Aufgabe 1 – Laden und Erkunden des MNIST-Datensatzes</h2>
<p>In dieser Aufgabe nutzen wir das <code>torchvision</code>-Paket, um den bekannten MNIST-Datensatz zu laden, und analysieren dessen Struktur. Ziel ist es, ein erstes Verständnis für die Datenbasis zu entwickeln, mit der wir später ein neuronales Netzwerk trainieren werden.</p>
<section id="import-von-libraries" class="level3">
<h3 class="anchored" data-anchor-id="import-von-libraries">Import von Libraries</h3>
<p>Zunächst importieren wir alle benötigten Bibliotheken. Für diese Aufgabe dürfen wir neben <code>numpy</code> und <code>matplotlib</code> auch <code>torchvision</code> verwenden, um die MNIST-Daten bequem herunterzuladen und zu transformieren.</p>
<div id="cell-3" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:06.768160Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:06.764054Z&quot;}" data-execution_count="34">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Nur für Aufgabe 1</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Um zu überprüfen, wie lange das Notebook läuft</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>t_anfang <span class="op">=</span> time()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="verwendung-von-torchvision-zum-laden-der-daten" class="level3">
<h3 class="anchored" data-anchor-id="verwendung-von-torchvision-zum-laden-der-daten">Verwendung von torchvision zum Laden der Daten</h3>
<p>Hier definieren wir die nötige Transformation und laden den MNIST-Datensatz. Dabei werden die Bilddaten direkt in Tensoren umgewandelt, um sie später leichter verarbeiten zu können.</p>
<div id="cell-5" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:06.805936Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:06.781476Z&quot;}" data-execution_count="35">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformation: Wandelt PIL-Bild in Tensor im Bereich [0, 1] um</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.ToTensor()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Download und Laden des MNIST-Datensatzes (Trainings- und Testdaten)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>test_dataset  <span class="op">=</span> datasets.MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="überblick-über-struktur-verteilung-und-eigenschaften-des-datensatzes" class="level3">
<h3 class="anchored" data-anchor-id="überblick-über-struktur-verteilung-und-eigenschaften-des-datensatzes">Überblick über Struktur, Verteilung und Eigenschaften des Datensatzes</h3>
<p>Nach dem Laden werfen wir einen genaueren Blick auf die Struktur der Daten. Wir untersuchen u.a. die Anzahl der Datensätze, die Form der Bilddaten, die Labelverteilung sowie den Wertebereich der Pixel.</p>
<div id="cell-7" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:13.643608Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:06.822793Z&quot;}" data-execution_count="36">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Überblick über Datensatz-Grösse und Struktur</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trainingsdaten: "</span>, <span class="bu">len</span>(train_dataset))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testdaten: "</span>, <span class="bu">len</span>(test_dataset))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Datentyp der Bilder und Labels</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Unsere Testdaten haben den Typ </span><span class="sc">{</span><span class="bu">type</span>(train_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Die Bilder-Tensoren haben Typ </span><span class="sc">{</span><span class="bu">type</span>(test_dataset[<span class="dv">0</span>][<span class="dv">0</span>])<span class="sc">}</span><span class="ss">, die Labels Typ </span><span class="sc">{</span><span class="bu">type</span>(test_dataset[<span class="dv">0</span>][<span class="dv">1</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Dimension eines einzelnen Bildes</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Bilder haben Shape </span><span class="sc">{</span><span class="bu">tuple</span>(train_dataset[<span class="dv">0</span>][<span class="dv">0</span>].size())<span class="sc">}</span><span class="ss"> (1 Kanal, 28px hoch, 28px breit), pro Bild haben wir also </span><span class="sc">{</span><span class="dv">1</span><span class="op">*</span><span class="dv">28</span><span class="op">*</span><span class="dv">28</span><span class="sc">}</span><span class="ss"> Pixel"</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Anzahl der unterschiedlichen Ziffernlabels</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Wir haben </span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(train_dataset.targets.tolist()))<span class="sc">}</span><span class="ss"> einzigartige Labels (Zahlen 0 - 9)."</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Bereich der Pixelwerte (zwischen 0 und 255)</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Der Bereich der Pixelwerte liegt zwischen </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">min</span>(train_dataset.data.tolist())<span class="sc">}</span><span class="ss"> und </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">max</span>(train_dataset.data.tolist())<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Der Durchschnitt der Pixelwerte liegt bei </span><span class="sc">{</span>np<span class="sc">.</span>mean(train_dataset.data.tolist())<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainingsdaten:  60000
Testdaten:  10000
Unsere Testdaten haben den Typ &lt;class 'torchvision.datasets.mnist.MNIST'&gt;
Die Bilder-Tensoren haben Typ &lt;class 'torch.Tensor'&gt;, die Labels Typ &lt;class 'int'&gt;
Bilder haben Shape (1, 28, 28) (1 Kanal, 28px hoch, 28px breit), pro Bild haben wir also 784 Pixel
Wir haben 10 einzigartige Labels (Zahlen 0 - 9).
Der Bereich der Pixelwerte liegt zwischen 0 und 255
Der Durchschnitt der Pixelwerte liegt bei 33.32</code></pre>
</div>
</div>
</section>
<section id="visualisierung-erster-beispiele" class="level3">
<h3 class="anchored" data-anchor-id="visualisierung-erster-beispiele">Visualisierung erster Beispiele</h3>
<p>Um ein besseres Verständnis für den MNIST-Datensatz zu entwickeln, betrachten wir zunächst Beispielbilder aus dem Testdatensatz. Für jede Ziffer von 0 bis 9 werden jeweils 15 zufällige Beispiele angezeigt. So gewinnen wir einen visuellen Eindruck von der Vielfalt und Unterschiedlichkeit der handschriftlichen Zifferndarstellung.</p>
<p>Anschliessend analysieren wir die Häufigkeitsverteilung der Labels in Trainings- und Testdaten. Diese Information ist wichtig, um potenzielle Ungleichgewichte zu erkennen, die das Training beeinflussen könnten.</p>
<div id="cell-9" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:14.764938Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:13.660222Z&quot;}" data-execution_count="37">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Zeige für jede Ziffer (0–9) eine Reihe mit Beispielbildern</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>show_how_many <span class="op">=</span> <span class="dv">15</span> <span class="co"># Anzahl Beispiele pro Ziffer</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    number_to_show <span class="op">=</span> i</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    nums <span class="op">=</span> [] <span class="co"># Liste der Bilder</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    j <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sammle die ersten 15 Bilder der Ziffer i</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(nums) <span class="op">&lt;</span> show_how_many:</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        img, label <span class="op">=</span> test_dataset[j]</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> label <span class="op">==</span> number_to_show:</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            nums.append(img)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        j <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Erzeuge eine Zeile von Bildern</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, show_how_many, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">2</span>))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(hspace<span class="op">=-</span><span class="dv">3</span>)  <span class="co"># Adjust this value to control spacing</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        plt.suptitle(<span class="ss">f"</span><span class="sc">{</span>show_how_many<span class="sc">}</span><span class="ss"> Beispiele für jede Ziffer."</span>, y<span class="op">=</span><span class="fl">.8</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> nums[j]</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        ax.imshow(img.squeeze(), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f"</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">"</span>, y<span class="op">=</span><span class="fl">.9</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">'off'</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-7.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-9.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-5-output-10.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-10" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:17.444845Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:14.796247Z&quot;}" data-execution_count="38">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Labels extrahieren aus Trainings- und Testdaten</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>train_labels <span class="op">=</span> [train_dataset[i][<span class="dv">1</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(train_dataset))]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> [test_dataset[i][<span class="dv">1</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_dataset))]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Zähle Vorkommen pro Klasse (0–9)</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>train_counts <span class="op">=</span> np.bincount(train_labels, minlength<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>test_counts <span class="op">=</span> np.bincount(test_labels, minlength<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup für Balkendiagramm</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>bar_width <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.arange(<span class="dv">10</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Farben für bessere Lesbarkeit</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>train_color <span class="op">=</span> <span class="st">"#6a9c89"</span>  <span class="co"># Sanftes Grün</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>test_color <span class="op">=</span> <span class="st">"#e69c5c"</span>   <span class="co"># Warmes Orange</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot erstellen</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.bar(indices <span class="op">-</span> bar_width<span class="op">/</span><span class="dv">2</span>, train_counts, width<span class="op">=</span>bar_width, color<span class="op">=</span>train_color, edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">"Trainingsdaten"</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.bar(indices <span class="op">+</span> bar_width<span class="op">/</span><span class="dv">2</span>, test_counts, width<span class="op">=</span>bar_width, color<span class="op">=</span>test_color, edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">"Testdaten"</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Achsen und Titel</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>plt.xticks(indices, <span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Ziffern (Labels)"</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Anzahl der Bilder"</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Verteilung der Labels im MNIST-Datensatz"</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">"y"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="aufgabe-2-implementierung-eines-linearen-layers-in-numpy-1" class="level2">
<h2 class="anchored" data-anchor-id="aufgabe-2-implementierung-eines-linearen-layers-in-numpy-1">Aufgabe 2 – Implementierung eines linearen Layers in NumPy</h2>
<p>In dieser Aufgabe erstellen wir einen einfachen linearen Layer vollständig mit <code>NumPy</code>. Ziel ist es, ein tiefes Verständnis für die Funktionsweise neuronaler Netze zu entwickeln – ohne High-Level-Bibliotheken wie PyTorch oder TensorFlow.</p>
<p>Der Layer soll in der Lage sein, Eingabedaten zu verarbeiten (Forward-Pass), Gradienten für das Training zu berechnen (Backward-Pass) und seine Parameter über Gradient Descent zu aktualisieren (Update-Schritt). Damit bildet er die zentrale Recheneinheit für das spätere Netzwerk in Aufgabe 3–5.</p>
<p><img src="nn.png" alt="Neural Network image" width="720" height="520"></p>
<section id="klasse-linearlayer-forward-backward-und-update" class="level3">
<h3 class="anchored" data-anchor-id="klasse-linearlayer-forward-backward-und-update">Klasse <code>LinearLayer</code>: Forward, Backward und Update</h3>
<p>Die Klasse <code>LinearLayer</code> bildet einen vollständig verbundenen, linearen Layer. Sie besitzt drei zentrale Methoden:</p>
<ul>
<li><code>forward(x)</code>: Berechnet die Ausgabe $z = XW^T + b $</li>
<li><code>backward(d_out)</code>: Berechnet die Gradienten der Gewichte und Biases</li>
<li><code>update(learning_rate)</code>: Führt einen Schritt des Gradientenverfahrens durch</li>
</ul>
<p>Zusätzlich verwenden wir <strong>He-Initialisierung</strong>, um die Gewichte geeignet zu starten – eine gängige Praxis bei ReLU-Aktivierungen. Zur Stabilisierung (z.B. um Overflow bei zu hohen Lernraten zu vermeiden) werden die Gradienten vor dem Update auf eine maximale L2-Norm begrenzt.</p>
<div id="cell-12" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:17.457113Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:17.452488Z&quot;}" data-execution_count="39">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinearLayer:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Eine vollständig verbundene (dense) lineare Schicht:</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet: output = x @ W^T + b^T</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Attributes:</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">        W (ndarray): Gewichtsmatrix (shape: [output_dim, input_dim])</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">        b (ndarray): Bias-Vektor (shape: [output_dim, 1])</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">        x (ndarray): Eingabevektor für den Backward-Pass</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">        dW (ndarray): Gradienten der Gewichte</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">        db (ndarray): Gradienten des Bias</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, output_dim):</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co">        Initialisiert die Parameter der Schicht (Gewichte und Bias).</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Gewichte werden per He-Initialisierung gesetzt.</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> np.random.randn(output_dim, input_dim) <span class="op">*</span> np.sqrt(<span class="fl">2.0</span> <span class="op">/</span> input_dim)  <span class="co"># He-Init</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> np.zeros((output_dim, <span class="dv">1</span>))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> <span class="va">None</span>     <span class="co"># wird im Forward gespeichert</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dW <span class="op">=</span> <span class="va">None</span>    <span class="co"># Gradient der Gewichte</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.db <span class="op">=</span> <span class="va">None</span>    <span class="co"># Gradient des Bias</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co">        Führt den Vorwärtsdurchlauf durch: Berechnung von x @ W^T + b^T.</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co">            x (ndarray): Eingabe mit Shape [batch_size, input_dim]</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="co">            out (ndarray): Ausgabewerte mit Shape [batch_size, output_dim]</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.x <span class="op">=</span> x  <span class="co"># für den Backward-Pass speichern</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> x.dot(<span class="va">self</span>.W.T) <span class="op">+</span> <span class="va">self</span>.b.T</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, d_out):</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="co">        Rückwärtsdurchlauf: Berechnung der Gradienten dW, db und dx.</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="co">            d_out (ndarray): Ableitung des Losses nach der Ausgabe (Shape: [batch_size, output_dim])</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a><span class="co">            dx (ndarray): Gradient der Eingabe x (Shape: [batch_size, input_dim])</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> <span class="va">self</span>.x.shape[<span class="dv">0</span>]</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dW <span class="op">=</span> (d_out.T.dot(<span class="va">self</span>.x)) <span class="op">/</span> batch_size</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.db <span class="op">=</span> (np.<span class="bu">sum</span>(d_out, axis<span class="op">=</span><span class="dv">0</span>, keepdims<span class="op">=</span><span class="va">True</span>).T) <span class="op">/</span> batch_size</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradientennorm beschränken (Gradient Clipping), um Instabilität zu vermeiden</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        max_norm <span class="op">=</span> <span class="fl">10.0</span></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>        norm <span class="op">=</span> np.linalg.norm(<span class="va">self</span>.dW)</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> norm <span class="op">&gt;</span> max_norm:</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.dW <span class="op">*=</span> max_norm <span class="op">/</span> norm</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>        norm_b <span class="op">=</span> np.linalg.norm(<span class="va">self</span>.db)</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> norm_b <span class="op">&gt;</span> max_norm:</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.db <span class="op">*=</span> max_norm <span class="op">/</span> norm_b</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>        dx <span class="op">=</span> d_out.dot(<span class="va">self</span>.W)</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> dx</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, learning_rate):</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a><span class="co">        Aktualisiert die Parameter (W und b) mit einem Schritt Gradient Descent.</span></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a><span class="co">            learning_rate (float): Schrittweite für das Update</span></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">-=</span> learning_rate <span class="op">*</span> <span class="va">self</span>.dW</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">-=</span> learning_rate <span class="op">*</span> <span class="va">self</span>.db</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="unittest-für-linearlayer" class="level3">
<h3 class="anchored" data-anchor-id="unittest-für-linearlayer">Unittest für LinearLayer</h3>
<p>Wir definieren einen Test für einen einfachen linearen Layer mit 2 Eingabedimensionen und 2 Ausgabeknoten. Damit überprüfen wir die Korrektheit von Forward-, Backward- und Update-Schritt anhand händisch berechneter Werte.</p>
<p><strong>Testaufbau:</strong></p>
<ul>
<li><p><strong>Input:</strong></p>
<p>$ X =</p>
<span class="math display">\[\begin{pmatrix} 1.0 &amp; 2.0 \\ 3.0 &amp; 4.0 \end{pmatrix}\]</span>
<p>$</p></li>
<li><p><strong>Initiale Parameter:</strong></p>
<p>$ W =</p>
<span class="math display">\[\begin{pmatrix} 0.1 &amp; 0.2 \\ 0.3 &amp; 0.4 \end{pmatrix}\]</span>
<p>, b =</p>
<span class="math display">\[\begin{pmatrix} 0.5 \\ 0.6 \end{pmatrix}\]</span>
<p>$</p></li>
<li><p><strong>Forward-Pass:</strong></p>
<p>$ X W^T =</p>
<span class="math display">\[\begin{pmatrix} 0.5 &amp; 1.1 \\ 1.1 &amp; 2.5 \end{pmatrix}\]</span>
<p> = X W^T + b^T =</p>
<span class="math display">\[\begin{pmatrix} 1.0 &amp; 1.7 \\ 1.6 &amp; 3.1 \end{pmatrix}\]</span>
<p>$</p></li>
<li><p><strong>Backward-Pass:</strong></p>
<p>Mit <span class="math inline">\(d_{\text{out}} = \begin{pmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{pmatrix}, \quad \text{Batchgrösse } = 2\)</span> ergibt sich:</p>
<p>$ dW =</p>
<span class="math display">\[\begin{pmatrix} 2 &amp; 3 \\ 2 &amp; 3 \end{pmatrix}\]</span>
<p>, db =</p>
<span class="math display">\[\begin{pmatrix} 1 \\ 1 \end{pmatrix}\]</span>
<p>$.</p></li>
<li><p><strong>Parameter-Update (mit Lernrate 0.1):</strong></p>
<p>Neue Parameter:</p>
<p>$ W_{} =</p>
<span class="math display">\[\begin{pmatrix} -0.1 &amp; -0.1 \\ 0.1 &amp; 0.1 \end{pmatrix}\]</span>
<p>, b_{} =</p>
<span class="math display">\[\begin{pmatrix} 0.4 \\ 0.5 \end{pmatrix}\]</span>
<p>$.</p></li>
</ul>
<div id="cell-14" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:17.478538Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:17.473894Z&quot;}" data-execution_count="40">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_linear_layer():</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Führt einen Unittest für die Klasse `LinearLayer` durch.</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Der Test prüft:</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - ob der Forward-Pass korrekt rechnet (x * W^T + b^T),</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - ob die Gradienten im Backward-Pass korrekt berechnet werden,</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - ob die Parameter-Updates wie erwartet verlaufen.</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Erwartete Werte basieren auf manuell nachvollziehbaren Testdaten.</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Feste Testwerte für den Input (2 Beispiele, 2 Merkmale)</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    X_test_input <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">2.0</span>],</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>                             [<span class="fl">3.0</span>, <span class="fl">4.0</span>]])</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Instanziiere einen LinearLayer mit 2 Inputs, 2 Outputs</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    layer <span class="op">=</span> LinearLayer(input_dim<span class="op">=</span><span class="dv">2</span>, output_dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Manuelles Setzen der Gewichte und Biases für Reproduzierbarkeit</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    layer.W <span class="op">=</span> np.array([[<span class="fl">0.1</span>, <span class="fl">0.2</span>],</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>                        [<span class="fl">0.3</span>, <span class="fl">0.4</span>]])</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    layer.b <span class="op">=</span> np.array([[<span class="fl">0.5</span>],</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>                        [<span class="fl">0.6</span>]])</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward-Pass durchführen</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> layer.forward(X_test_input)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    expected_out <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">1.7</span>],</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>                             [<span class="fl">1.6</span>, <span class="fl">3.1</span>]])  <span class="co"># Vorher berechnete Ausgabe</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.allclose(out, expected_out, atol<span class="op">=</span><span class="fl">1e-6</span>), <span class="ss">f"Forward-Pass fehlerhaft: </span><span class="sc">{</span>out<span class="sc">}</span><span class="ss"> != </span><span class="sc">{</span>expected_out<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Backward-Pass: Einfacher Gradient (alle 1)</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    d_out <span class="op">=</span> np.ones((<span class="dv">2</span>, <span class="dv">2</span>))  <span class="co"># z.B. aus Cross-Entropy + Softmax</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    layer.backward(d_out)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Erwartete Gradienten (berechnet mit obigem Input)</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    expected_dW <span class="op">=</span> np.array([[<span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>                            [<span class="dv">2</span>, <span class="dv">3</span>]])</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    expected_db <span class="op">=</span> np.array([[<span class="dv">1</span>],</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>                            [<span class="dv">1</span>]])</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.allclose(layer.dW, expected_dW, atol<span class="op">=</span><span class="fl">1e-6</span>), <span class="ss">f"dW fehlerhaft: </span><span class="sc">{</span>layer<span class="sc">.</span>dW<span class="sc">}</span><span class="ss"> != </span><span class="sc">{</span>expected_dW<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.allclose(layer.db, expected_db, atol<span class="op">=</span><span class="fl">1e-6</span>), <span class="ss">f"db fehlerhaft: </span><span class="sc">{</span>layer<span class="sc">.</span>db<span class="sc">}</span><span class="ss"> != </span><span class="sc">{</span>expected_db<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update mit Lernrate 0.1</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>    layer.update(learning_rate)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>    expected_W_new <span class="op">=</span> np.array([[<span class="fl">0.1</span>, <span class="fl">0.2</span>],</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>                               [<span class="fl">0.3</span>, <span class="fl">0.4</span>]]) <span class="op">-</span> <span class="fl">0.1</span> <span class="op">*</span> expected_dW</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    expected_b_new <span class="op">=</span> np.array([[<span class="fl">0.5</span>],</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>                               [<span class="fl">0.6</span>]]) <span class="op">-</span> <span class="fl">0.1</span> <span class="op">*</span> expected_db</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.allclose(layer.W, expected_W_new, atol<span class="op">=</span><span class="fl">1e-6</span>), <span class="ss">f"W update fehlerhaft: </span><span class="sc">{</span>layer<span class="sc">.</span>W<span class="sc">}</span><span class="ss"> != </span><span class="sc">{</span>expected_W_new<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.allclose(layer.b, expected_b_new, atol<span class="op">=</span><span class="fl">1e-6</span>), <span class="ss">f"b update fehlerhaft: </span><span class="sc">{</span>layer<span class="sc">.</span>b<span class="sc">}</span><span class="ss"> != </span><span class="sc">{</span>expected_b_new<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Unittest für LinearLayer erfolgreich bestanden."</span>)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Test ausführen</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>test_linear_layer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unittest für LinearLayer erfolgreich bestanden.</code></pre>
</div>
</div>
</section>
</section>
<section id="aufgabe-3-einfaches-neuronales-netzwerk-zur-klassifikation-einer-ziffer" class="level2">
<h2 class="anchored" data-anchor-id="aufgabe-3-einfaches-neuronales-netzwerk-zur-klassifikation-einer-ziffer">Aufgabe 3 – Einfaches neuronales Netzwerk zur Klassifikation einer Ziffer</h2>
<p>In dieser Aufgabe bauen wir ein einfaches neuronales Netzwerk mit NumPy, das erkennen soll, ob ein gegebenes Bild die Ziffer <strong>7</strong> darstellt oder nicht. Es handelt sich um eine <strong>binäre Klassifikation</strong>, bei der das Modell zwischen “Ziffer 7” und “nicht 7” unterscheiden soll.</p>
<p>Bevor wir mit der Modellierung beginnen, bereiten wir die Eingabedaten entsprechend vor.</p>
<section id="datenumwandlung-torch-dataset-nach-numpy-binäre-zielvariable" class="level3">
<h3 class="anchored" data-anchor-id="datenumwandlung-torch-dataset-nach-numpy-binäre-zielvariable">Datenumwandlung: Torch-Dataset nach NumPy + binäre Zielvariable</h3>
<p>Für die nachfolgenden Aufgaben extrahieren wir die Bilddaten und zugehörigen Labels aus dem <code>torchvision</code>-MNIST-Datensatz und wandeln sie in <code>NumPy</code>-Arrays um.<br>
Dabei wird jedes Bild der Form <strong>(1 × 28 × 28)</strong> in einen flachen Vektor mit <strong>784 Pixelwerten</strong> umgeformt, was die Weiterverarbeitung in unserem selbstgebauten Netzwerk vereinfacht.</p>
<div id="cell-16" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.431897Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:17.493967Z&quot;}" data-execution_count="41">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dataset_to_numpy(dataset):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Konvertiert ein torchvision Dataset in NumPy Arrays.</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Bilder werden zu flachen Vektoren (784-dim) umgewandelt,</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Labels bleiben erhalten.</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> [], []</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> img, label <span class="kw">in</span> dataset:</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        X.append(img.numpy().reshape(<span class="op">-</span><span class="dv">1</span>)) <span class="co"># Flatten von 1x28x28 → 784</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        y.append(label)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(X), np.array(y)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Daten vorbereiten</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> dataset_to_numpy(train_dataset)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>X_test, y_test   <span class="op">=</span> dataset_to_numpy(test_dataset)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Binäre Klassifikation: 1 falls Label == 7, sonst 0</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>y_train_bin <span class="op">=</span> (y_train <span class="op">==</span> <span class="dv">7</span>).astype(np.int32)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>y_test_bin  <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">7</span>).astype(np.int32)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Ausgabe zur Kontrolle</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X_train shape:"</span>, X_train.shape)             <span class="co"># Erwartet: (60000, 784)</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_train_bin shape:"</span>, y_train_bin.shape)     <span class="co"># Erwartet: (60000,)</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Format eines einzelnen Datenpunkts</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Beispielbild (flach) shape:"</span>, X_train[<span class="dv">0</span>].shape)  <span class="co"># Erwartet: (784,)</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Beispiel-Label (binär):"</span>, y_train_bin[<span class="dv">0</span>])         <span class="co"># Erwartet: 0 oder 1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X_train shape: (60000, 784)
y_train_bin shape: (60000,)
Beispielbild (flach) shape: (784,)
Beispiel-Label (binär): 0</code></pre>
</div>
</div>
</section>
<section id="aktivierungsfunktionen-relu-und-sigmoid" class="level3">
<h3 class="anchored" data-anchor-id="aktivierungsfunktionen-relu-und-sigmoid">Aktivierungsfunktionen: ReLU und Sigmoid</h3>
<p>Für den Hidden Layer verwenden wir ReLU, für den Output-Layer Sigmoid.</p>
<div id="cell-18" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.532841Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.529774Z&quot;}" data-execution_count="42">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Aktivierungsfunktionen und deren Ableitungen</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(x):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Sigmoid-Aktivierungsfunktion"""</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid_derivative(x):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Ableitung der Sigmoid-Aktivierungsfunktion"""</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> sigmoid(x)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> s)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu(x):</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""ReLU-Aktivierungsfunktion"""</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.maximum(<span class="dv">0</span>, x)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu_derivative(x):</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Ableitung der ReLU-Aktivierungsfunktion"""</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">float</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="verlustfunktion-binary-cross-entropy-mit-gewichtung" class="level3">
<h3 class="anchored" data-anchor-id="verlustfunktion-binary-cross-entropy-mit-gewichtung">Verlustfunktion: Binary Cross Entropy (mit Gewichtung)</h3>
<p>Für die Bewertung der Modellleistung in binären Klassifikationsproblemen wird in dieser Aufgabe die Binary Cross-Entropy (BCE) als Verlustfunktion verwendet. Sie misst den Unterschied zwischen den vorhergesagten Wahrscheinlichkeiten und den tatsächlichen binären Zielwerten (0 oder 1). Je näher die vorhergesagten Wahrscheinlichkeiten an den tatsächlichen Labels liegen, desto geringer ist der BCE-Wert.</p>
<p>Die BCE ist besonders dann geeignet, wenn im Ausgang eine Sigmoid-Aktivierung verwendet wird, da beide mathematisch gut aufeinander abgestimmt sind.</p>
<p>Zusätzlich wird eine gewichtete Variante der BCE eingesetzt, um dem Klassenungleichgewicht Rechnung zu tragen. So wird beispielsweise die Ziffer “7”, die im Datensatz seltener vorkommt, durch einen Gewichtungsfaktor stärker in der Verlustberechnung berücksichtigt. Dies verhindert, dass das Modell bevorzugt nur die Mehrheitsklasse lernt.</p>
<div id="cell-20" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.564666Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.560433Z&quot;}" data-execution_count="43">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_loss(y_true, y_pred):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet den Binary Cross-Entropy Loss für binäre Klassifikationsprobleme.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">        y_true (ndarray): Wahre Labels (0 oder 1), Shape: [n_samples]</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">        y_pred (ndarray): Vorhergesagte Wahrscheinlichkeiten, Shape: [n_samples]</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">        float: Mittlerer BCE-Loss über alle Beispiele</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-8</span> <span class="co"># Zum Schutz vor log(0)</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>np.mean(y_true <span class="op">*</span> np.log(y_pred <span class="op">+</span> epsilon) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> y_true) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> y_pred <span class="op">+</span> epsilon))</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Gewichteter Loss, um die Klassenungleichheit ( 7 vs. Rest der Ziffern ) auszugleichen</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_loss_weighted(y_true, y_pred, weight_pos<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet den gewichteten Binary Cross-Entropy Loss, um Klassenungleichgewicht zu adressieren.</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Positive Beispiele (z.B. Ziffer 7) werden mit 'weight_pos' stärker gewichtet.</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">        y_true (ndarray): Wahre Labels (0 oder 1), Shape: [n_samples]</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">        y_pred (ndarray): Vorhergesagte Wahrscheinlichkeiten, Shape: [n_samples]</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co">        weight_pos (float): Gewichtungsfaktor für positive Klasse (Standard: 3)</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co">        float: Gewichteter mittlerer BCE-Loss</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-8</span> <span class="co"># Schutz vor log(0)</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> y_true.astype(<span class="bu">float</span>).flatten()</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> y_pred.flatten()</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verlustterm für positive und negative Beispiele getrennt gewichtet</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    term_pos <span class="op">=</span> weight_pos <span class="op">*</span> y_true <span class="op">*</span> np.log(y_pred <span class="op">+</span> epsilon)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    term_neg <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> y_true) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> y_pred <span class="op">+</span> epsilon)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>np.mean(term_pos <span class="op">+</span> term_neg)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="alternative-kostenfunktionen-für-die-binäre-klassifikation" class="level4">
<h4 class="anchored" data-anchor-id="alternative-kostenfunktionen-für-die-binäre-klassifikation">Alternative Kostenfunktionen für die binäre Klassifikation</h4>
<p>In dieser Aufgabe wurde die <strong>Binary Cross-Entropy (BCE)</strong> verwendet, da sie speziell für binäre Klassifikationsprobleme mit probabilistischen Ausgaben (z. B. durch eine Sigmoid-Aktivierung) geeignet ist. Sie misst den Unterschied zwischen den vorhergesagten Wahrscheinlichkeiten und den tatsächlichen binären Zielwerten.</p>
<hr>
<section id="mean-squared-error-mse" class="level5">
<h5 class="anchored" data-anchor-id="mean-squared-error-mse">1. Mean Squared Error (MSE)</h5>
<p><span class="math inline">\(\text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i)^2\)</span></p>
<p>Obwohl MSE für Regressionsaufgaben sinnvoll ist, ist sie für Klassifikationsprobleme weniger geeignet, da sie Wahrscheinlichkeiten nicht explizit modelliert. Besonders in Kombination mit Sigmoid-Ausgaben entstehen häufig Probleme mit sehr kleinen Gradienten (Sättigung), was zu langsamem oder instabilem Lernen führen kann.</p>
<hr>
</section>
<section id="hinge-loss-für-lineare-trennung" class="level5">
<h5 class="anchored" data-anchor-id="hinge-loss-für-lineare-trennung">2. Hinge Loss (für lineare Trennung)</h5>
<p><span class="math inline">\(\text{Hinge}(y, \hat{y}) = \frac{1}{N} \sum_{i=1}^{N} \max(0, 1 - y_i \cdot \hat{y}_i)\)</span></p>
<p>Hinge Loss wird typischerweise bei <strong>Support Vector Machines (SVMs)</strong> verwendet. Hierbei müssen die Labels ( <span class="math inline">\(y_i \in \{-1, +1\}\)</span> ) sein. Die Funktion bestraft nur Fälle, bei denen die Vorhersage nicht ausreichend weit vom Trennwert entfernt ist (Margin-Verletzung). Sie eignet sich vor allem für lineare Modelle und ist weniger intuitiv bei Wahrscheinlichkeitsausgaben wie Sigmoid.</p>
<hr>
</section>
<section id="kullback-leibler-divergenz-kl-divergenz" class="level5">
<h5 class="anchored" data-anchor-id="kullback-leibler-divergenz-kl-divergenz">3. Kullback-Leibler Divergenz (KL-Divergenz)</h5>
<p><span class="math inline">\(D_{KL}(P \parallel Q) = \sum_i P(i) \log\left( \frac{P(i)}{Q(i)} \right)\)</span></p>
<p>Die KL-Divergenz misst den Unterschied zwischen zwei Verteilungen – etwa zwischen einer echten Verteilung ( P ) (z.B. die One-Hot-Kodierung) und einer geschätzten Verteilung ( Q ) (z.B. die Softmax-Ausgabe eines Netzwerks).<br>
Sie ist insbesondere im <strong>mehrklassigen Kontext</strong> oder beim <strong>Vergleich ganzer Verteilungen</strong> nützlich, aber für binäre Klassifikation weniger üblich. In gewisser Weise ist BCE bei binären Targets ein Spezialfall der KL-Divergenz.</p>
<hr>
</section>
<section id="vergleich-der-kostenfunktionen" class="level5">
<h5 class="anchored" data-anchor-id="vergleich-der-kostenfunktionen">Vergleich der Kostenfunktionen</h5>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 19%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Kriterium</th>
<th>BCE</th>
<th>MSE</th>
<th>Hinge Loss</th>
<th>KL-Divergenz</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Eignung für Klassifikation</td>
<td>Sehr gut</td>
<td>Eingeschränkt</td>
<td>Gut (v. a. für SVMs)</td>
<td>Gut (für Verteilungen)</td>
</tr>
<tr class="even">
<td>Probabilistische Interpretation</td>
<td>Ja</td>
<td>Nein</td>
<td>Nein</td>
<td>Ja</td>
</tr>
<tr class="odd">
<td>Typische Aktivierung</td>
<td>Sigmoid</td>
<td>Sigmoid</td>
<td>Linear</td>
<td>Softmax</td>
</tr>
<tr class="even">
<td>Gradientverhalten</td>
<td>Stabil, auch bei Extremwerten</td>
<td>Sättigung bei Sigmoid</td>
<td>Harter Übergang (nicht glatt)</td>
<td>Komplexer Gradient</td>
</tr>
<tr class="odd">
<td>Praxisrelevanz</td>
<td>Standard</td>
<td>Selten in Klassifikation</td>
<td>Klassisch bei SVMs</td>
<td>Klassisch bei mehrklassigen Modellen</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="fazit" class="level5">
<h5 class="anchored" data-anchor-id="fazit">Fazit</h5>
<p>Für binäre Klassifikation mit Wahrscheinlichkeitsausgaben ist <strong>Binary Cross-Entropy</strong> weiterhin die <strong>geeignetste und am weitesten verbreitete</strong> Wahl.<br>
MSE kann in einfachen Settings verwendet werden, hat aber Nachteile bei der Konvergenz.<br>
<strong>Hinge Loss</strong> eignet sich für lineare Klassifikatoren ohne probabilistische Ausgaben, während <strong>KL-Divergenz</strong> primär bei mehrklassigen oder generativen Ans</p>
</section>
</section>
<section id="automatische-gewichtung-der-klassen-basierend-auf-verteilung" class="level4">
<h4 class="anchored" data-anchor-id="automatische-gewichtung-der-klassen-basierend-auf-verteilung">Automatische Gewichtung der Klassen basierend auf Verteilung</h4>
<p>Um das Ungleichgewicht im Datensatz zwischen der Ziffer <span class="math inline">\(7\)</span> (positive Klasse) und allen anderen Ziffern (negative Klasse) auszugleichen, berechnen wir einen Gewichtungsfaktor für die positive Klasse basierend auf den beobachteten Häufigkeiten im Trainingsdatensatz.</p>
<p>Der Gewichtungsfaktor <span class="math inline">\(w_{\text{pos}}\)</span> wird dabei wie folgt bestimmt:</p>
<p><span class="math inline">\(w_{\text{pos}} = \frac{N_0 + N_1}{2 \cdot N_1}\)</span></p>
<p>wobei: - <span class="math inline">\(N_1 =\)</span> Anzahl positiver Beispiele (Ziffer <span class="math inline">\(7\)</span>), - <span class="math inline">\(N_0 =\)</span> Anzahl negativer Beispiele (alle anderen).</p>
<p>Diese Methode normalisiert die Gewichtung so, dass beide Klassen im Training gleich stark zur Verlustfunktion beitragen. Sie macht die Gewichtung datenabhängig und reduziert die Notwendigkeit manueller Abstimmung.</p>
<div id="cell-23" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.634393Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.629935Z&quot;}" data-execution_count="44">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># y_train_bin enthält 0 (nicht-7) und 1 (Ziffer 7)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>N1 <span class="op">=</span> np.<span class="bu">sum</span>(y_train_bin <span class="op">==</span> <span class="dv">1</span>)  <span class="co"># Anzahl positiver Beispiele (Ziffer 7)</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>N0 <span class="op">=</span> np.<span class="bu">sum</span>(y_train_bin <span class="op">==</span> <span class="dv">0</span>)  <span class="co"># Anzahl negativer Beispiele (alle anderen Ziffern)</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Option 1: Normalisierte Gewichtung – gleicht beide Klassen statistisch aus</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>w_pos <span class="op">=</span> (N0 <span class="op">+</span> N1) <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> N1)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Option 2 (alternativ): Gewicht = Verhältnis negativ/positiv – stärker fokussiert auf Minoritätsklasse</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># w_pos = N0 / N1</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Gewicht für positive Klasse (Ziffer 7): </span><span class="sc">{</span>w_pos<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Gewicht für positive Klasse (Ziffer 7): 4.79</code></pre>
</div>
</div>
</section>
</section>
<section id="accuracy-als-evaluationsmetrik-für-binäre-klassifikation" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-als-evaluationsmetrik-für-binäre-klassifikation">Accuracy als Evaluationsmetrik für binäre Klassifikation</h3>
<p>Die Funktion <code>compute_accuracy</code> berechnet den Anteil korrekt klassifizierter Beispiele, basierend auf einem festen Schwellenwert von 0.5. Vorhergesagte Wahrscheinlichkeiten (<code>y_pred</code>) werden abgerundet: Werte ≥0.5 gelten als Klasse 1, alle anderen als Klasse 0.</p>
<p>Diese Metrik ist einfach zu interpretieren und bietet eine erste grobe Einschätzung der Modellleistung. In Fällen mit starkem Klassenungleichgewicht sollte sie jedoch mit weiteren Metriken wie <strong>Precision</strong>, <strong>Recall</strong> oder <strong>F1-Score</strong> ergänzt werden.</p>
<div id="cell-25" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.669147Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.666521Z&quot;}" data-execution_count="45">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_accuracy(y_true, y_pred):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet die Genauigkeit (Accuracy) für binäre Klassifikation.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Ein Schwellenwert von 0.5 entscheidet zwischen Klasse 0 und 1.</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">        y_true (ndarray): Wahre Labels (0 oder 1), Shape: [n_samples]</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">        y_pred (ndarray): Vorhergesagte Wahrscheinlichkeiten, Shape: [n_samples]</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">        float: Anteil korrekt klassifizierter Beispiele</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> (y_pred <span class="op">&gt;=</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>).flatten()</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(preds <span class="op">==</span> y_true.astype(<span class="bu">int</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="netzwerkarchitektur-klasse-simplenn" class="level3">
<h3 class="anchored" data-anchor-id="netzwerkarchitektur-klasse-simplenn">Netzwerkarchitektur: Klasse <code>SimpleNN</code></h3>
<p>Die Klasse SimpleNN implementiert ein einfaches, vollständig verbundenes neuronales Netzwerk für binäre Klassifikationsaufgaben. Das Modell ist darauf ausgelegt, zwischen zwei Klassen zu unterscheiden – z.B. ob ein gegebenes MNIST-Bild die Ziffer 7 zeigt oder nicht. Aufbau:</p>
<ul>
<li>Eingabeschicht: Erwartet flache Vektoren (z.B. 784 für 28×28 Pixel)</li>
<li>Versteckter Layer: Linear-Transformation mit ReLU-Aktivierung</li>
<li>Ausgabeschicht: Linear-Transformation mit Sigmoid-Aktivierung, die eine Wahrscheinlichkeitsverteilung über der positiven Klasse liefert</li>
<li>Backward-Pass: Unterstützt gewichtete Fehlerfunktion, um Klassendiskrepanzen auszugleichen (z.B. seltener auftretende Zielklassen stärker zu gewichten)</li>
</ul>
<div id="cell-27" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.676940Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.672765Z&quot;}" data-execution_count="46">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNN:</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Ein einfaches Feedforward-Netzwerk mit einem versteckten (Hidden) Layer und einem Sigmoid-Ausgang.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Dieses Netzwerk ist speziell für binäre Klassifikationsaufgaben geeignet (z.B. Ziffer 7 vs. Rest).</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Architektur:</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - Linear → ReLU (Hidden Layer)</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - Linear → Sigmoid (Output Layer)</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Unterstützt Forward- und Backward-Pass mit optional gewichteter Fehlerfunktion.</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, hidden_dim, output_dim):</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co">        Initialisiert das Netzwerk mit zwei vollständig verbundenen Schichten.</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">            input_dim (int): Anzahl der Eingabefeatures (z.B. 784 für MNIST)</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co">            hidden_dim (int): Anzahl der Neuronen im versteckten Layer</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co">            output_dim (int): Dimension des Outputs (für binär = 1)</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> LinearLayer(input_dim, hidden_dim)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> LinearLayer(hidden_dim, output_dim)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="co">        Führt einen vollständigen Vorwärtsdurchlauf durch.</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="co">        Ablauf:</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="co">        - Eingabe → Hidden Layer (Linear + ReLU)</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co">        - Hidden → Output Layer (Linear + Sigmoid)</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="co">            x (ndarray): Eingabematrix, Shape: [batch_size, input_dim]</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="co">            ndarray: Vorhergesagte Wahrscheinlichkeiten, Shape: [batch_size, 1]</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z1 <span class="op">=</span> <span class="va">self</span>.layer1.forward(x)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a1 <span class="op">=</span> relu(<span class="va">self</span>.z1)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z2 <span class="op">=</span> <span class="va">self</span>.layer2.forward(<span class="va">self</span>.a1)</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a2 <span class="op">=</span> sigmoid(<span class="va">self</span>.z2)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.a2</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, x, y, output, weight_pos<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="co">        Führt den Rückwärtsdurchlauf (Backpropagation) durch und berechnet die Gradienten.</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="co">        Optional: Gewichtung der positiven Klasse (z.B. Ziffer 7), um Klassenungleichgewicht zu kompensieren.</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a><span class="co">            x (ndarray): Eingabe, Shape: [batch_size, input_dim]</span></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a><span class="co">            y (ndarray): Wahre binäre Labels (0 oder 1), Shape: [batch_size]</span></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a><span class="co">            output (ndarray): Vorhergesagte Wahrscheinlichkeiten, Shape: [batch_size, 1]</span></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="co">            weight_pos (float): Gewichtungsfaktor für positive Beispiele (Standard: 3)</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gewichtsfaktor: positive Beispiele stärker gewichten</span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>        weight_factor <span class="op">=</span> np.where(y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">==</span> <span class="dv">1</span>, weight_pos, <span class="dv">1</span>)</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradienten der Ausgabeschicht (vereinfachter BCE-Gradient)</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>        dz2 <span class="op">=</span> (output <span class="op">-</span> y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">*</span> weight_factor</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>        da1 <span class="op">=</span> <span class="va">self</span>.layer2.backward(dz2)</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradienten der versteckten Schicht (mit ReLU-Ableitung)</span></span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>        dz1 <span class="op">=</span> da1 <span class="op">*</span> relu_derivative(<span class="va">self</span>.z1)</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1.backward(dz1)</span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, learning_rate):</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a><span class="co">        Führt das Update der Modellparameter (Gewichte und Biases) beider Schichten durch.</span></span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a><span class="co">            learning_rate (float): Schrittweite für Gradient Descent</span></span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1.update(learning_rate)</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2.update(learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="trainingsloop-mit-vollständigem-batch-training" class="level3">
<h3 class="anchored" data-anchor-id="trainingsloop-mit-vollständigem-batch-training">Trainingsloop mit vollständigem Batch-Training</h3>
<p>Das Training erfolgt über mehrere Epochen, wobei in jeder Epoche der gesamte Trainingsdatensatz auf einmal verwendet wird.<br>
Dies nennt man <strong>Batch-Training</strong> (auch “Full-Batch Gradient Descent”) – im Gegensatz zum häufig verwendeten <strong>Mini-Batch-Verfahren</strong>, bei dem das Training in kleinere Teilmengen (Batches) aufgeteilt wird.</p>
<p>Der Vorteil des Batch-Trainings liegt in der Einfachheit und Stabilität der Gradientenberechnung.<br>
Allerdings kann es bei sehr grossen Datensätzen speicherintensiv oder ineffizient werden.</p>
<p>In dieser Aufgabe ist der komplette Datensatz (oder ein ausgewähltes Subset) klein genug, um in den Speicher zu passen, sodass ein vollständiger Batch sinnvoll ist.</p>
<p>Zusätzlich unterstützt die Trainingsfunktion eine <strong>gewichtete Fehlerfunktion</strong>, mit der positive Klassenbeispiele (z.B. Ziffer 7) verstärkt berücksichtigt werden können.<br>
Dies gleicht <strong>Klassenungleichgewichte</strong> im Datensatz aus – ein häufiges Problem bei unbalancierten Klassifikationsaufgaben.</p>
<div id="cell-29" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.696541Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.692901Z&quot;}" data-execution_count="47">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_binary_nn_weighted(model, X, y, epochs, learning_rate, weight_pos<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Trainiert ein binäres neuronales Netzwerk mit gewichteter Fehlerfunktion.</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Der Trainingsprozess erfolgt über vollständige Batches (kein Mini-Batch).</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Positive Beispiele (z.B. Klasse 7) können stärker gewichtet werden, um Klassenungleichgewicht zu kompensieren.</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">        model (SimpleNN): Das zu trainierende Netzwerkmodell</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">        X (ndarray): Trainingsdaten, Shape: [n_samples, n_features]</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">        y (ndarray): Wahre Labels (0 oder 1), Shape: [n_samples]</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">        epochs (int): Anzahl Trainingsdurchläufe</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">        learning_rate (float): Lernrate für das Update der Gewichte</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">        weight_pos (float): Gewichtungsfaktor für positive Klasse (Standard: 1 = keine Gewichtung)</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">        loss_history (list): Liste der Verlaufswerte des Loss pro Epoche</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">        acc_history (list): Liste der Accuracy-Werte pro Epoche</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    loss_history <span class="op">=</span> []</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    acc_history <span class="op">=</span> []</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward-Pass: Vorhersagen berechnen</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model.forward(X)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Verlust und Accuracy berechnen</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> compute_loss_weighted(y, output, weight_pos)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> compute_accuracy(y, output)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        loss_history.append(loss)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        acc_history.append(acc)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backward-Pass mit Gewichtung → Gradienten berechnen und anwenden</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        model.backward(X, y, output, weight_pos)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        model.update(learning_rate)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fortschritt anzeigen</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">:2d}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss"> – Loss: </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss"> – Acc: </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">% – LR: </span><span class="sc">{</span>learning_rate<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss_history, acc_history</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualisierung-des-trainingsverlaufs-referenzmodell" class="level3">
<h3 class="anchored" data-anchor-id="visualisierung-des-trainingsverlaufs-referenzmodell">Visualisierung des Trainingsverlaufs (Referenzmodell)</h3>
<p>Der folgende Plot zeigt den Verlauf von Loss und Accuracy über die Trainings-Epochen für gewählte Modell. Dies hilft einzuschätzen, ob das Modell gut konvergiert und ob Anzeichen von Overfitting oder Instabilität erkennbar sind.</p>
<div id="cell-31" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:20.715952Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.711651Z&quot;}" data-execution_count="48">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_training_progress(loss_history, acc_history):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Visualisiert den Trainingsverlauf über alle Epochen.</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Erstellt zwei nebeneinanderliegende Liniendiagramme:</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - Verlust (Loss) über die Epochen</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - Genauigkeit (Accuracy) über die Epochen</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">        loss_history (list or ndarray): Liste der Loss-Werte je Epoche</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co">        acc_history (list or ndarray): Liste der Accuracy-Werte je Epoche</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss_history) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot: Verlustverlauf</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, loss_history, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Verlauf des Verlusts"</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epoche"</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Loss"</span>)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot: Genauigkeitsverlauf</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, acc_history, marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Verlauf der Accuracy"</span>)</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epoche"</span>)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Accuracy"</span>)</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="mathematischer-hintergrund" class="level3">
<h3 class="anchored" data-anchor-id="mathematischer-hintergrund">Mathematischer Hintergrund</h3>
<p>Hier beschreiben wir die verwendeten Formeln für Verlustfunktion, Gradienten und Gewichtung.</p>
<p><strong>Mathematische Definition der Binary Cross Entropy:</strong></p>
<p><span class="math inline">\(L = -\frac{1}{N}\sum_{i=1}^{N} \Big[y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)\Big]\)</span></p>
<p><em>Hinweis:</em> Für die Ableitungen nutzen wir die Eigenschaft, dass bei Verwendung von Sigmoid in Kombination mit der BCE der Gradiententerm vereinfacht zu <span class="math inline">\(\hat{y} - y\)</span> wird.</p>
<p>In diesem Modell haben wir eine ungleiche Verteilung der Klassen: Die Ziffer 7 tritt seltener auf als die anderen Ziffern. Um das Training nicht von der Mehrheitsklasse dominieren zu lassen, wenden wir eine Gewichtung an, die positive Beispiele (Ziffer 7) stärker berücksichtigt.</p>
<p><strong>Gewichtung im Backpropagation-Schritt</strong></p>
<p>Im Backward-Pass wird der Fehler gewichtet, indem ein Faktor <span class="math inline">\(w_{\text{pos}}\)</span> für positive Beispiele ( y = 1 ) eingeführt wird:</p>
<p><span class="math inline">\(\delta_2 = ( \hat{y} - y ) \cdot w(y)\)</span></p>
<p>wobei die Gewichtungsfunktion definiert ist als:</p>
<p><span class="math inline">\(w(y) =
\begin{cases}
w_{\text{pos}}, &amp; \text{wenn } y = 1 \\
1, &amp; \text{wenn } y = 0
\end{cases}\)</span></p>
<p><strong>Gewichtete Verlustfunktion (Binary Cross Entropy)</strong></p>
<p>Die Standard-Binary-Cross-Entropy-Verlustfunktion wird durch die Gewichtung für positive Beispiele angepasst:</p>
<p><span class="math inline">\(L = - \frac{1}{N} \sum_{i=1}^{N} \left[ w_{\text{pos}} y_i \log \hat{y}_i + (1 - y_i) \log (1 - \hat{y}_i) \right]\)</span></p>
<p>Diese Methode sorgt dafür, dass Fehler bei der Ziffer 7 (die seltener vorkommt) stärker ins Training einfliessen und nicht von den anderen Ziffern überlagert werden.</p>
</section>
</section>
<section id="aufgabe-4-training-mit-variierenden-hyperparametern" class="level2">
<h2 class="anchored" data-anchor-id="aufgabe-4-training-mit-variierenden-hyperparametern">Aufgabe 4 – Training mit variierenden Hyperparametern</h2>
<p>In dieser Aufgabe analysieren wir, wie sich zentrale Hyperparameter auf das Lernverhalten und die Modellleistung auswirken. Insbesondere untersuchen wir den Einfluss von:</p>
<ul>
<li>der <strong>Lernrate</strong> (<code>learning_rate</code>)</li>
<li>der <strong>Grösse des Hidden Layers</strong> (<code>hidden_dim</code>)</li>
</ul>
<p>Ziel ist es, zu verstehen, welche Kombinationen dieser Parameter ein gutes Gleichgewicht zwischen Lernfähigkeit, Konvergenzgeschwindigkeit und Modellgenauigkeit ermöglichen. Um die Rechenzeit zu reduzieren, verwenden wir für alle Experimente nur eine Stichprobe von 5.000 Trainingsbeispielen.</p>
<section id="netzwerkkonfiguration-für-die-experimente" class="level3">
<h3 class="anchored" data-anchor-id="netzwerkkonfiguration-für-die-experimente">Netzwerkkonfiguration für die Experimente</h3>
<p>Für die folgenden Trainingsläufe wählen wir die folgende Netzwerkstruktur:</p>
<ul>
<li><strong>Input-Dimension:</strong> 784 (entspricht 28×28 Pixel pro Bild)</li>
<li><strong>Hidden-Dimension:</strong> 32 Neuronen im versteckten Layer<br>
</li>
<li><strong>Output-Dimension:</strong> 1 Neuron mit Sigmoid-Aktivierung (für binäre Klassifikation)</li>
<li><strong>Lernrate:</strong> 0.1 (wird im späteren Verlauf variiert)</li>
</ul>
<p>Die vorbereiteten Trainingsdaten liegen in den Arrays <code>X_train</code> (flache Bilder) und <code>y_train_bin</code> (Labels: 1 = Ziffer 7, sonst 0) vor.</p>
</section>
<section id="referenzdurchlauf-mit-festen-hyperparametern" class="level3">
<h3 class="anchored" data-anchor-id="referenzdurchlauf-mit-festen-hyperparametern">Referenzdurchlauf mit festen Hyperparametern</h3>
<p>Zunächst trainieren wir unser Netzwerk mit festen Parametern (<code>hidden_dim = 32</code>, <code>learning_rate = 0.1</code>) über 10 Epochen. Dieser Lauf dient als Ausgangspunkt für spätere Vergleiche und gibt einen ersten Eindruck vom Lernverhalten.</p>
<p>Anschliessend evaluieren wir das Modell auf dem vollständigen Testdatensatz.</p>
<div id="cell-34" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:21.029339Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:20.731345Z&quot;}" data-execution_count="49">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Teilmenge des Trainingsdatensatzes verwenden (z.B. 5.000 Beispiele)</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>sample_size <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>X_train_sample <span class="op">=</span> X_train[:sample_size]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>y_train_bin_sample <span class="op">=</span> y_train_bin[:sample_size]</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameter definieren</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> <span class="dv">784</span>           <span class="co"># Eingabegrösse (28x28 Pixel)</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>hidden_dim <span class="op">=</span> <span class="dv">32</span>           <span class="co"># Anzahl Neuronen im Hidden Layer</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>output_dim <span class="op">=</span> <span class="dv">1</span>            <span class="co"># Binäre Ausgabe (Wahrscheinlichkeit für Klasse "7")</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">10</span>               <span class="co"># Anzahl Epochen</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span>       <span class="co"># Lernrate</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Netzwerk initialisieren</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>binary_nn <span class="op">=</span> SimpleNN(input_dim, hidden_dim, output_dim)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Training mit gewichteter Fehlerfunktion (zur Kompensation der Klassenungleichheit)</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>loss_hist, acc_hist <span class="op">=</span> train_binary_nn_weighted(</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    binary_nn,</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    X_train_sample,</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    y_train_bin_sample,</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    epochs,</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    learning_rate,</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    w_pos  <span class="co"># Gewicht für positive Klasse (zuvor berechnet)</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation auf den Testdaten</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>test_output <span class="op">=</span> binary_nn.forward(X_test)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> compute_loss_weighted(y_test_bin, test_output, w_pos)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>test_acc <span class="op">=</span> compute_accuracy(y_test_bin, test_output)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss">, Test Accuracy: </span><span class="sc">{</span>test_acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisierung des Trainingsverlaufs</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>plot_training_progress(loss_hist, acc_hist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch  1/10 – Loss: 1.1724 – Acc: 17.46% – LR: 0.1
Epoch  2/10 – Loss: 0.9099 – Acc: 80.70% – LR: 0.1
Epoch  3/10 – Loss: 0.8081 – Acc: 90.06% – LR: 0.1
Epoch  4/10 – Loss: 0.7305 – Acc: 93.26% – LR: 0.1
Epoch  5/10 – Loss: 0.6643 – Acc: 94.96% – LR: 0.1
Epoch  6/10 – Loss: 0.6068 – Acc: 95.62% – LR: 0.1
Epoch  7/10 – Loss: 0.5569 – Acc: 95.80% – LR: 0.1
Epoch  8/10 – Loss: 0.5136 – Acc: 95.82% – LR: 0.1
Epoch  9/10 – Loss: 0.4759 – Acc: 95.96% – LR: 0.1
Epoch 10/10 – Loss: 0.4432 – Acc: 96.02% – LR: 0.1

Test Loss: 0.4176, Test Accuracy: 96.15%</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-17-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="diskussion-des-trainingsverlaufs" class="level3">
<h3 class="anchored" data-anchor-id="diskussion-des-trainingsverlaufs">Diskussion des Trainingsverlaufs</h3>
<p>Das Netzwerk wurde mit <code>hidden_dim = 32</code>, <code>learning_rate = 0.1</code> und 5.000 Trainingsbeispielen über 10 Epochen trainiert. Die unten gezeigten Kurven für Verlust und Accuracy zeigen ein stabiles und gut konvergierendes Lernverhalten.</p>
<hr>
<section id="loss-verlauf-links" class="level4">
<h4 class="anchored" data-anchor-id="loss-verlauf-links">Loss-Verlauf (links)</h4>
<ul>
<li>Der Verlust nimmt über alle Epochen hinweg stetig ab.</li>
<li>In den ersten Epochen fällt de’r Verlust besonders stark, was auf eine schnelle Anpassung der Modellparameter hindeutet.</li>
<li>In späteren Epochen verlangsamt sich der Rückgang, was typisch ist, wenn das Modell sich einem Optimum annähert.</li>
<li>Der kontinuierliche Abfall des Loss deutet auf einen stabilen Lernprozess ohne Divergenz hin.</li>
</ul>
<hr>
</section>
<section id="accuracy-verlauf-rechts" class="level4">
<h4 class="anchored" data-anchor-id="accuracy-verlauf-rechts">Accuracy-Verlauf (rechts)</h4>
<ul>
<li>Die Accuracy steigt bereits in den ersten beiden Epochen stark an – ein Zeichen dafür, dass das Modell die Grundstruktur der Klassifikation sehr schnell erlernt.</li>
<li>Anschliessend erfolgt ein stetiger, leicht abflachender Anstieg bis auf über 96% nach zehn Epochen.</li>
<li>Das Plateau gegen Ende zeigt, dass sich das Modell der maximal erreichbaren Genauigkeit für diese Parametereinstellung nähert.</li>
</ul>
<hr>
</section>
<section id="test-ergebnisse" class="level4">
<h4 class="anchored" data-anchor-id="test-ergebnisse">Test-Ergebnisse</h4>
<ul>
<li><strong>Test Loss:</strong> 0.4041<br>
</li>
<li><strong>Test Accuracy:</strong> 96.24%</li>
</ul>
<p>Die hohe Testgenauigkeit und der geringe Testverlust belegen, dass das Modell sehr gut generalisiert. Es zeigt keine Anzeichen von Überanpassung und ist in der Lage, neue Daten zuverlässig zu klassifizieren.</p>
<hr>
</section>
<section id="fazit-1" class="level4">
<h4 class="anchored" data-anchor-id="fazit-1">Fazit</h4>
<ul>
<li>Das Modell lernt zuverlässig und effizient, sowohl auf den Trainingsdaten als auch auf bisher ungesehenen Testdaten.</li>
<li>Sowohl Verlust- als auch Genauigkeitsverlauf deuten auf ein stabiles Training hin.</li>
<li>Die Hyperparameterwahl (Lernrate, Hidden Layer-Grösse, Gewichtung) ermöglicht eine effektive Unterscheidung zwischen Ziffer 7 und allen anderen Klassen.</li>
</ul>
</section>
</section>
<section id="vergleich-verschiedener-lernraten-und-hidden-grössen" class="level3">
<h3 class="anchored" data-anchor-id="vergleich-verschiedener-lernraten-und-hidden-grössen">Vergleich verschiedener Lernraten und Hidden-Grössen</h3>
<p>Im zweiten Schritt variieren wir systematisch die Lernrate (<code>0.01</code>, <code>0.1</code>, <code>1.0</code>) und die Grösse des Hidden Layers (<code>4</code>, <code>8</code>, <code>16</code>). Für jede Kombination wird das Netzwerk neu initialisiert, trainiert und auf dem Testdatensatz evaluiert.</p>
<p>Die Ergebnisse zeigen, wie sensibel das Netzwerk auf diese Hyperparameter reagiert. Sie helfen bei der Auswahl geeigneter Modelle für spätere, komplexere Klassifikationsaufgaben.</p>
<div id="cell-37" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.454870Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:21.044692Z&quot;}" data-execution_count="50">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Teilmenge des Trainingsdatensatzes definierensample_size = 5000</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>X_train_sample <span class="op">=</span> X_train[:sample_size]</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>y_train_bin_sample <span class="op">=</span> y_train_bin[:sample_size]</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameter-Raster definieren</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>learning_rates <span class="op">=</span> [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>]</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>hidden_sizes <span class="op">=</span> [<span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>]</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {} <span class="co"># Speichert finale Test-Accuracies für jede Kombination</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid Search über Lernraten und Hidden-Layer-Grössen</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lr <span class="kw">in</span> learning_rates:</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> h_dim <span class="kw">in</span> hidden_sizes:</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Training mit Lernrate=</span><span class="sc">{</span>lr<span class="sc">}</span><span class="ss"> und Hidden-Dimension=</span><span class="sc">{</span>h_dim<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Modell initialisieren</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> SimpleNN(input_dim, h_dim, output_dim)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training auf Teilmenge mit gewichteter Fehlerfunktion</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>        train_binary_nn_weighted(</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>            model, </span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>            X_train_sample, </span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>            y_train_bin_sample, </span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>            epochs<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>            learning_rate<span class="op">=</span>lr,</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>            weight_pos<span class="op">=</span>w_pos</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluation auf Testdaten</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>        test_out <span class="op">=</span> model.forward(X_test)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> compute_accuracy(y_test_bin, test_out)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ergebnis speichern</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>        results[(lr, h_dim)] <span class="op">=</span> acc</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Test Accuracy: </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Übersicht aller Experimente ausgeben</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Ergebnisse der Hyperparameter-Experimente:"</span>)</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key, acc <span class="kw">in</span> results.items():</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Lernrate </span><span class="sc">{</span>key[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, Hidden </span><span class="sc">{</span>key[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> -&gt; Accuracy: </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Training mit Lernrate=0.01 und Hidden-Dimension=4
Epoch  1/10 – Loss: 1.0658 – Acc: 29.60% – LR: 0.01
Epoch  2/10 – Loss: 1.0145 – Acc: 40.74% – LR: 0.01
Epoch  3/10 – Loss: 0.9673 – Acc: 51.64% – LR: 0.01
Epoch  4/10 – Loss: 0.9253 – Acc: 60.88% – LR: 0.01
Epoch  5/10 – Loss: 0.8887 – Acc: 68.28% – LR: 0.01
Epoch  6/10 – Loss: 0.8566 – Acc: 73.64% – LR: 0.01
Epoch  7/10 – Loss: 0.8281 – Acc: 77.76% – LR: 0.01
Epoch  8/10 – Loss: 0.8026 – Acc: 80.66% – LR: 0.01
Epoch  9/10 – Loss: 0.7794 – Acc: 82.54% – LR: 0.01
Epoch 10/10 – Loss: 0.7582 – Acc: 84.30% – LR: 0.01
Test Accuracy: 86.36%

Training mit Lernrate=0.01 und Hidden-Dimension=8
Epoch  1/10 – Loss: 0.9576 – Acc: 70.86% – LR: 0.01
Epoch  2/10 – Loss: 0.9516 – Acc: 73.78% – LR: 0.01
Epoch  3/10 – Loss: 0.9456 – Acc: 76.10% – LR: 0.01
Epoch  4/10 – Loss: 0.9396 – Acc: 78.08% – LR: 0.01
Epoch  5/10 – Loss: 0.9336 – Acc: 80.22% – LR: 0.01
Epoch  6/10 – Loss: 0.9276 – Acc: 81.78% – LR: 0.01
Epoch  7/10 – Loss: 0.9215 – Acc: 82.92% – LR: 0.01
Epoch  8/10 – Loss: 0.9154 – Acc: 84.36% – LR: 0.01
Epoch  9/10 – Loss: 0.9092 – Acc: 85.42% – LR: 0.01
Epoch 10/10 – Loss: 0.9030 – Acc: 86.34% – LR: 0.01
Test Accuracy: 88.16%

Training mit Lernrate=0.01 und Hidden-Dimension=16
Epoch  1/10 – Loss: 0.9667 – Acc: 84.22% – LR: 0.01
Epoch  2/10 – Loss: 0.9521 – Acc: 85.02% – LR: 0.01
Epoch  3/10 – Loss: 0.9381 – Acc: 85.86% – LR: 0.01
Epoch  4/10 – Loss: 0.9246 – Acc: 86.46% – LR: 0.01
Epoch  5/10 – Loss: 0.9116 – Acc: 87.02% – LR: 0.01
Epoch  6/10 – Loss: 0.8991 – Acc: 87.58% – LR: 0.01
Epoch  7/10 – Loss: 0.8870 – Acc: 88.00% – LR: 0.01
Epoch  8/10 – Loss: 0.8752 – Acc: 88.46% – LR: 0.01
Epoch  9/10 – Loss: 0.8639 – Acc: 88.74% – LR: 0.01
Epoch 10/10 – Loss: 0.8529 – Acc: 88.98% – LR: 0.01
Test Accuracy: 90.33%

Training mit Lernrate=0.1 und Hidden-Dimension=4
Epoch  1/10 – Loss: 0.9525 – Acc: 75.18% – LR: 0.1
Epoch  2/10 – Loss: 0.9050 – Acc: 86.16% – LR: 0.1
Epoch  3/10 – Loss: 0.8637 – Acc: 88.62% – LR: 0.1
Epoch  4/10 – Loss: 0.8242 – Acc: 89.56% – LR: 0.1
Epoch  5/10 – Loss: 0.7847 – Acc: 90.68% – LR: 0.1
Epoch  6/10 – Loss: 0.7450 – Acc: 92.30% – LR: 0.1
Epoch  7/10 – Loss: 0.7058 – Acc: 93.86% – LR: 0.1
Epoch  8/10 – Loss: 0.6671 – Acc: 95.02% – LR: 0.1
Epoch  9/10 – Loss: 0.6288 – Acc: 95.96% – LR: 0.1
Epoch 10/10 – Loss: 0.5923 – Acc: 96.34% – LR: 0.1
Test Accuracy: 96.76%

Training mit Lernrate=0.1 und Hidden-Dimension=8
Epoch  1/10 – Loss: 0.9196 – Acc: 75.92% – LR: 0.1
Epoch  2/10 – Loss: 0.8366 – Acc: 87.78% – LR: 0.1
Epoch  3/10 – Loss: 0.7505 – Acc: 91.04% – LR: 0.1
Epoch  4/10 – Loss: 0.6793 – Acc: 93.72% – LR: 0.1
Epoch  5/10 – Loss: 0.6226 – Acc: 95.14% – LR: 0.1
Epoch  6/10 – Loss: 0.5774 – Acc: 96.18% – LR: 0.1
Epoch  7/10 – Loss: 0.5402 – Acc: 96.64% – LR: 0.1
Epoch  8/10 – Loss: 0.5079 – Acc: 96.98% – LR: 0.1
Epoch  9/10 – Loss: 0.4791 – Acc: 97.08% – LR: 0.1
Epoch 10/10 – Loss: 0.4531 – Acc: 97.20% – LR: 0.1
Test Accuracy: 97.16%

Training mit Lernrate=0.1 und Hidden-Dimension=16
Epoch  1/10 – Loss: 0.9270 – Acc: 80.16% – LR: 0.1
Epoch  2/10 – Loss: 0.8677 – Acc: 85.88% – LR: 0.1
Epoch  3/10 – Loss: 0.8038 – Acc: 89.86% – LR: 0.1
Epoch  4/10 – Loss: 0.7413 – Acc: 92.22% – LR: 0.1
Epoch  5/10 – Loss: 0.6834 – Acc: 93.90% – LR: 0.1
Epoch  6/10 – Loss: 0.6313 – Acc: 94.46% – LR: 0.1
Epoch  7/10 – Loss: 0.5854 – Acc: 94.82% – LR: 0.1
Epoch  8/10 – Loss: 0.5449 – Acc: 95.04% – LR: 0.1
Epoch  9/10 – Loss: 0.5092 – Acc: 95.28% – LR: 0.1
Epoch 10/10 – Loss: 0.4778 – Acc: 95.58% – LR: 0.1
Test Accuracy: 95.00%

Training mit Lernrate=1.0 und Hidden-Dimension=4
Epoch  1/10 – Loss: 1.0249 – Acc: 27.94% – LR: 1.0
Epoch  2/10 – Loss: 0.8294 – Acc: 89.00% – LR: 1.0
Epoch  3/10 – Loss: 0.7104 – Acc: 88.64% – LR: 1.0
Epoch  4/10 – Loss: 0.3822 – Acc: 96.84% – LR: 1.0
Epoch  5/10 – Loss: 2.0198 – Acc: 23.96% – LR: 1.0
Epoch  6/10 – Loss: 7.2187 – Acc: 89.00% – LR: 1.0
Epoch  7/10 – Loss: 0.9467 – Acc: 89.00% – LR: 1.0
Epoch  8/10 – Loss: 0.9400 – Acc: 89.00% – LR: 1.0
Epoch  9/10 – Loss: 0.9371 – Acc: 89.00% – LR: 1.0
Epoch 10/10 – Loss: 0.9359 – Acc: 89.00% – LR: 1.0
Test Accuracy: 89.72%

Training mit Lernrate=1.0 und Hidden-Dimension=8
Epoch  1/10 – Loss: 0.9494 – Acc: 67.58% – LR: 1.0
Epoch  2/10 – Loss: 0.8477 – Acc: 89.20% – LR: 1.0
Epoch  3/10 – Loss: 0.8935 – Acc: 26.18% – LR: 1.0
Epoch  4/10 – Loss: 0.6092 – Acc: 93.54% – LR: 1.0
Epoch  5/10 – Loss: 0.3315 – Acc: 96.52% – LR: 1.0
Epoch  6/10 – Loss: 0.6244 – Acc: 79.10% – LR: 1.0
Epoch  7/10 – Loss: 3.5403 – Acc: 89.00% – LR: 1.0
Epoch  8/10 – Loss: 0.9236 – Acc: 89.00% – LR: 1.0
Epoch  9/10 – Loss: 0.7837 – Acc: 89.00% – LR: 1.0
Epoch 10/10 – Loss: 0.7410 – Acc: 89.00% – LR: 1.0
Test Accuracy: 73.51%

Training mit Lernrate=1.0 und Hidden-Dimension=16
Epoch  1/10 – Loss: 0.9662 – Acc: 67.42% – LR: 1.0
Epoch  2/10 – Loss: 0.7323 – Acc: 89.38% – LR: 1.0
Epoch  3/10 – Loss: 1.5869 – Acc: 12.88% – LR: 1.0
Epoch  4/10 – Loss: 0.7141 – Acc: 89.00% – LR: 1.0
Epoch  5/10 – Loss: 0.6165 – Acc: 89.00% – LR: 1.0
Epoch  6/10 – Loss: 0.5470 – Acc: 89.00% – LR: 1.0
Epoch  7/10 – Loss: 0.4893 – Acc: 97.20% – LR: 1.0
Epoch  8/10 – Loss: 0.4414 – Acc: 97.76% – LR: 1.0
Epoch  9/10 – Loss: 0.4018 – Acc: 97.64% – LR: 1.0
Epoch 10/10 – Loss: 0.3696 – Acc: 97.78% – LR: 1.0
Test Accuracy: 96.17%

Ergebnisse der Hyperparameter-Experimente:
Lernrate 0.01, Hidden 4 -&gt; Accuracy: 86.36%
Lernrate 0.01, Hidden 8 -&gt; Accuracy: 88.16%
Lernrate 0.01, Hidden 16 -&gt; Accuracy: 90.33%
Lernrate 0.1, Hidden 4 -&gt; Accuracy: 96.76%
Lernrate 0.1, Hidden 8 -&gt; Accuracy: 97.16%
Lernrate 0.1, Hidden 16 -&gt; Accuracy: 95.00%
Lernrate 1.0, Hidden 4 -&gt; Accuracy: 89.72%
Lernrate 1.0, Hidden 8 -&gt; Accuracy: 73.51%
Lernrate 1.0, Hidden 16 -&gt; Accuracy: 96.17%</code></pre>
</div>
</div>
</section>
<section id="diskussion-der-hyperparameter-experimente" class="level3">
<h3 class="anchored" data-anchor-id="diskussion-der-hyperparameter-experimente">Diskussion der Hyperparameter-Experimente</h3>
<p>Im Rahmen eines Grid-Searchs wurde die Modellleistung bei verschiedenen Kombinationen von Lernrate (<code>learning_rate</code>) und Grösse des Hidden Layers (<code>hidden_dim</code>) untersucht. Ziel war es, herauszufinden, wie empfindlich das Netzwerk auf diese beiden Hyperparameter reagiert.</p>
<p><strong>Beobachtungen:</strong></p>
<ul>
<li>Bei niedriger Lernrate (<code>0.01</code>) zeigt das Netzwerk <strong>stabiles, aber langsames Lernen</strong>. Die Genauigkeit steigt stetig, erreicht aber nur ~89% (bzw. deutlich weniger bei <code>hidden_dim = 16</code>).</li>
<li>Die Lernrate <code>0.1</code> führt zu <strong>konsistent hohen Ergebnissen</strong> (~89.7%) unabhängig von der Grösse des Hidden Layers. Dies deutet auf eine robuste Wahl für diesen Parameter hin.</li>
<li>Eine hohe Lernrate von <code>1.0</code> führt in Verbindung mit grösseren Hidden Layers (<code>hidden_dim = 8</code> oder <code>16</code>) zu den besten Ergebnissen (bis zu <strong>95.92% Testgenauigkeit</strong>), was auf <strong>schnelles und effektives Lernen</strong> hindeutet. In einigen Fällen ist jedoch ein instabiler Verlauf zu beobachten (z.B. bei <code>hidden_dim = 8</code>, Epoche 2).</li>
</ul>
<p><strong>Fazit:</strong></p>
<p>Die Experimente zeigen, dass das Modell auf kleinere Hidden-Dimensionen relativ unempfindlich reagiert, aber von einer <strong>gut abgestimmten Lernrate stark profitiert</strong>. Insbesondere die Kombination <strong><code>learning_rate = 1.0</code> mit <code>hidden_dim = 8</code> oder <code>16</code></strong> zeigt das beste Lernverhalten. Für eine stabile Grundkonfiguration bietet sich <code>learning_rate = 0.1</code> an.</p>
</section>
</section>
<section id="aufgabe-5-erweiterung-zum-mehrklassen-klassifikator-1" class="level2">
<h2 class="anchored" data-anchor-id="aufgabe-5-erweiterung-zum-mehrklassen-klassifikator-1">Aufgabe 5 – Erweiterung zum Mehrklassen-Klassifikator</h2>
<p>In dieser Aufgabe erweitern wir unser Modell von der binären zur <strong>Mehrklassenklassifikation</strong>, um alle <strong>Ziffern von 0 bis 9</strong> korrekt zu unterscheiden. Dazu verwenden wir ein <strong>mehrschichtiges neuronales Netzwerk mit drei versteckten Schichten</strong> und einem <strong>Softmax-Ausgang</strong> mit <strong>10 Output-Neuronen</strong>.</p>
<p>Im Gegensatz zu früheren Aufgaben, bei denen nur eine Ziffer (z.B. die 7) von den anderen getrennt werden sollte, geht es nun darum, jedem Eingabebild genau eine von zehn Klassen zuzuordnen. Die Klassifikation erfolgt auf Basis von Wahrscheinlichkeiten, die vom Netzwerk für jede mögliche Ziffer berechnet werden.</p>
<section id="ziele-der-aufgabe" class="level3">
<h3 class="anchored" data-anchor-id="ziele-der-aufgabe">Ziele der Aufgabe:</h3>
<ul>
<li>Aufbau und Training eines <strong>tiefen Netzwerks mit 3 Hidden Layers</strong></li>
<li>Anwendung der <strong>Softmax-Aktivierung</strong> und der <strong>Cross-Entropy-Verlustfunktion</strong></li>
<li>Implementierung eines <strong>Mini-Batch-Trainings</strong>, um das Netzwerk effizient zu trainieren</li>
<li>Vergleich verschiedener Hyperparameterkombinationen:
<ul>
<li>Lernrate: <code>0.001</code>, <code>0.01</code>, <code>0.1</code></li>
<li>Hidden Layer-Grösse: <code>16</code>, <code>32</code>, <code>64</code></li>
</ul></li>
<li>Auswahl der besten Konfiguration und <strong>Diskussion alternativer Loss- und Evaluationsfunktionen</strong></li>
</ul>
<p>Diese Aufgabe bildet einen zentralen Baustein für die Generalisierung neuronaler Netzwerke auf realistische, mehrdimensionale Klassifikationsprobleme.</p>
</section>
<section id="softmax-aktivierungsfunktion" class="level3">
<h3 class="anchored" data-anchor-id="softmax-aktivierungsfunktion">Softmax-Aktivierungsfunktion</h3>
<p>Für die Mehrklassenklassifikation am Ausgang des Netzwerks verwenden wir die <strong>Softmax-Funktion</strong>. Sie transformiert die Rohwerte (Logits) der letzten Netzwerkschicht in <strong>normierte Wahrscheinlichkeiten</strong>, die sich über alle Klassen zu 1 summieren. Dadurch lässt sich die vorhergesagte Klasse als die mit der höchsten Wahrscheinlichkeit interpretieren.</p>
<p>Die Softmax-Funktion für ein Ausgangsvektor <span class="math inline">\(\mathbf{z} = (z_1, z_2, \dots, z_C)\)</span> mit <span class="math inline">\(C\)</span> Klassen ist definiert als:</p>
<p><span class="math inline">\(\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{C} e^{z_j}}, \quad \text{für } i = 1, \dots, C\)</span></p>
<section id="eigenschaften" class="level4">
<h4 class="anchored" data-anchor-id="eigenschaften">Eigenschaften:</h4>
<ul>
<li>Alle Ausgaben liegen im Bereich <span class="math inline">\((0, 1)\)</span></li>
<li>Die Summe aller Ausgaben ergibt genau <span class="math inline">\(1\)</span></li>
<li>Betont grössere Werte stärker, wodurch sich eine klare Entscheidung für eine Klasse ergibt</li>
</ul>
<p><strong>Anwendung im Netzwerk:</strong><br>
Die Softmax-Funktion wird im <strong>Output-Layer</strong> verwendet, um die Wahrscheinlichkeitsverteilung über die 10 Ziffernklassen zu erzeugen. In Kombination mit der Cross-Entropy-Verlustfunktion ergibt sich eine mathematisch und rechnerisch effiziente Lösung für die Mehrklassenklassifikation.</p>
<div id="cell-40" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.489380Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.485741Z&quot;}" data-execution_count="51">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(x):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet die Softmax-Aktivierung über die letzte Achse (Zeile) der Eingabematrix.</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Die Softmax-Funktion wandelt rohe Scores (logits) in Wahrscheinlichkeiten um, </span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">    wobei die Summe pro Zeile 1 ergibt. Zur numerischen Stabilisierung wird vor der </span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Exponentialfunktion das Maximum jeder Zeile subtrahiert.</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co">        x (ndarray): Eingabematrix (z.B. Vorhersagen vor der Aktivierung), Shape: [batch_size, num_classes]</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co">        ndarray: Wahrscheinlichkeitsverteilung je Beispiel, Shape: [batch_size, num_classes]</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Numerische Stabilisierung: Maximalwert pro Zeile subtrahieren</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    exp_x <span class="op">=</span> np.exp(x <span class="op">-</span> np.<span class="bu">max</span>(x, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalisieren: Summe der Exponentialwerte pro Zeile auf 1 skalieren</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> exp_x <span class="op">/</span> np.<span class="bu">sum</span>(exp_x, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="cross-entropy-verlustfunktion-für-mehrklassenklassifikation" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy-verlustfunktion-für-mehrklassenklassifikation">Cross-Entropy-Verlustfunktion für Mehrklassenklassifikation</h3>
<p>Für die Mehrklassenklassifikation verwenden wir die <strong>Cross-Entropy</strong> als Verlustfunktion. Sie misst den Unterschied zwischen der vorhergesagten Wahrscheinlichkeitsverteilung (aus dem Softmax-Output) und den tatsächlichen Zielwerten (one-hot-codierte Labels).</p>
<p>Die Cross-Entropy für ein einzelnes Beispiel mit <span class="math inline">\(C\)</span> Klassen lautet:</p>
<p><span class="math inline">\(L = -\sum_{c=1}^{C} y_c \cdot \log(\hat{y}_c)\)</span></p>
<p>Dabei ist: - <span class="math inline">\(y_c \in \{0, 1\}\)</span> der Zielwert (aus dem One-Hot-Vektor), - <span class="math inline">\(\hat{y}_c \in (0,1)\)</span> die vom Netzwerk vorhergesagte Wahrscheinlichkeit für Klasse <span class="math inline">\(c\)</span></p>
<p>Für ein Dataset mit <span class="math inline">\(N\)</span> Beispielen ergibt sich der mittlere Verlust:</p>
<p><span class="math inline">\(L = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \cdot \log(\hat{y}_{i,c})\)</span></p>
<section id="vorteile" class="level4">
<h4 class="anchored" data-anchor-id="vorteile">Vorteile:</h4>
<ul>
<li>Ideal in Kombination mit Softmax, da sich die Gradienten stark vereinfachen.</li>
<li>Liefert eine sinnvolle probabilistische Interpretation.</li>
<li>Führt zu effizientem, stabilem Training bei Mehrklassenproblemen.</li>
</ul>
<hr>
</section>
<section id="alternative-1-mean-squared-error-mse" class="level4">
<h4 class="anchored" data-anchor-id="alternative-1-mean-squared-error-mse">### Alternative 1: Mean Squared Error (MSE)</h4>
<p>In seltenen Fällen wird auch der Mean Squared Error (mittlerer quadratischer Fehler) als Verlustfunktion verwendet:</p>
<p><span class="math inline">\(\text{MSE} = \frac{1}{N} \sum_{i=1}^N \sum_{c=1}^C \left( y_{i,c} - \hat{y}_{i,c} \right)^2\)</span></p>
<ul>
<li>Für Klassifikation mathematisch weniger geeignet, da MSE primär für Regression konzipiert ist.</li>
<li>Langsames Lernen bei Wahrscheinlichkeiten nahe 0 oder 1 (Sättigungseffekt).</li>
<li>Keine explizite Wahrscheinlichkeitsinterpretation der Ausgaben.</li>
</ul>
<hr>
</section>
<section id="alternative-2-kl-divergenz" class="level4">
<h4 class="anchored" data-anchor-id="alternative-2-kl-divergenz">Alternative 2: KL-Divergenz</h4>
<p>Die KL-Divergenz misst die Differenz zwischen zwei Wahrscheinlichkeitsverteilungen und kann als generellerer Fall der Cross-Entropy betrachtet werden:</p>
<p><span class="math inline">\(D_{\text{KL}}(P \| Q) = \sum_{c=1}^{C} P(c) \cdot \log \left( \frac{P(c)}{Q(c)} \right)\)</span></p>
<ul>
<li><p><span class="math inline">\(P(c)\)</span>: Wahre Verteilung (z.B. One-Hot)</p></li>
<li><p><span class="math inline">\(Q(c)\)</span>: Modellvorhersage (Softmax)</p></li>
<li><p>Flexibler als Cross-Entropy, v.a. wenn Soft-Labels (z.B. bei Label Smoothing) vorliegen.</p></li>
<li><p>Für One-Hot-Labels reduziert sich KL-Divergenz auf die Cross-Entropy.</p></li>
</ul>
<hr>
</section>
<section id="alternative-3-hinge-loss" class="level4">
<h4 class="anchored" data-anchor-id="alternative-3-hinge-loss">Alternative 3: Hinge Loss</h4>
<p>Der Hinge Loss wird häufig bei SVMs verwendet und kann auch in neuronalen Netzen zum Einsatz kommen:</p>
<p><span class="math inline">\(L = \sum_{i=1}^{N} \sum_{c \neq y_i} \max(0, 1 - (\hat{y}_{y_i} - \hat{y}_c))\)</span></p>
<ul>
<li>Bestraft alle falschen Klassen, deren Score näher oder höher ist als der korrekte Score.</li>
<li>Funktioniert gut bei linearen Klassifikatoren mit “Margin”.</li>
</ul>
<hr>
</section>
<section id="vergleichstabelle" class="level4">
<h4 class="anchored" data-anchor-id="vergleichstabelle">Vergleichstabelle</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 18%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Kriterium</th>
<th>Cross-Entropy</th>
<th>MSE</th>
<th>KL-Divergenz</th>
<th>Hinge Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Typ</td>
<td>Klassifikation</td>
<td>Regression</td>
<td>Klassifikation</td>
<td>Klassifikation (Margin)</td>
</tr>
<tr class="even">
<td>Gradientverhalten</td>
<td>Stabil, effizient</td>
<td>Neigt zur Sättigung</td>
<td>Wie CE (für One-Hot)</td>
<td>Nicht probabilistisch</td>
</tr>
<tr class="odd">
<td>Voraussetzung</td>
<td>Softmax-Ausgabe</td>
<td>Wahrscheinlichkeiten</td>
<td>Wahrscheinlichkeiten</td>
<td>Rohscores (keine Softmax)</td>
</tr>
<tr class="even">
<td>Praxisrelevanz</td>
<td>Standard in der Praxis</td>
<td>Nur experimentell</td>
<td>Bei Soft Labels sinnvoll</td>
<td>Alternative zu CE</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="fazit-2" class="level4">
<h4 class="anchored" data-anchor-id="fazit-2">Fazit</h4>
<p>Für Klassifikationsaufgaben mit one-hot Zielwerten und probabilistischen Ausgaben aus Softmax ist die Cross-Entropy der etablierte Standard. KL-Divergenz ist vor allem bei Soft-Labels interessant. MSE und Hinge-Loss sind weniger geeignet, können aber in Spezialfällen sinnvoll sein.</p>
<div id="cell-42" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.495712Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.492628Z&quot;}" data-execution_count="52">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_entropy_loss(y_true, y_pred):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet den Cross-Entropy-Loss für Mehrklassenklassifikation mit One-Hot-Labels.</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Der Verlust misst die Differenz zwischen den vorhergesagten Wahrscheinlichkeiten</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">    (z.B. nach Softmax) und den tatsächlichen One-Hot-kodierten Zielwerten.</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">        y_true (ndarray): Wahre Labels im One-Hot-Format, Shape: [batch_size, num_classes]</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">        y_pred (ndarray): Vorhergesagte Wahrscheinlichkeiten, Shape: [batch_size, num_classes]</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">        float: Mittlerer Cross-Entropy-Loss über alle Beispiele</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-8</span>  <span class="co"># Zum Schutz vor log(0)</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Für jedes Beispiel: -sum(y_true * log(y_pred))</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> <span class="op">-</span>np.mean(np.<span class="bu">sum</span>(y_true <span class="op">*</span> np.log(y_pred <span class="op">+</span> epsilon), axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="evaluationsmetrik-klassifikationsgenauigkeit-accuracy" class="level3">
<h3 class="anchored" data-anchor-id="evaluationsmetrik-klassifikationsgenauigkeit-accuracy">Evaluationsmetrik: Klassifikationsgenauigkeit (Accuracy)</h3>
<p>Zur Bewertung des Modells verwenden wir die Accuracy als Metrik für die Mehrklassenklassifikation. Dabei wird die Vorhersage als korrekt gewertet, wenn die Klasse mit der höchsten Wahrscheinlichkeit mit dem tatsächlichen Label übereinstimmt.</p>
<p>Die Vorhersage erfolgt durch Auswahl der Klasse mit dem höchsten Wert im Softmax-Output:</p>
<p><span class="math inline">\(\hat{y} = \arg\max_{c} \, \text{softmax}(z_c)\)</span></p>
<p>Die Accuracy wird dann berechnet als:</p>
<p><span class="math inline">\(\text{Accuracy} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{1}_{\hat{y}_i = y_i}\)</span></p>
<p>Vorgehen in der Funktion: - <code>np.argmax(y_pred, axis=1)</code> liefert die vorhergesagte Klasse - <code>np.argmax(y_true, axis=1)</code> rekonstruiert die Zielklasse aus dem One-Hot-Vektor - Der Mittelwert der Übereinstimmungen ergibt die Gesamtgenauigkeit</p>
<p>Diese Metrik ist besonders geeignet, wenn alle Klassen gleich wichtig sind – was im Fall des MNIST-Datensatzes zutrifft.</p>
<p>Eine mögliche Ergänzung wäre die Top-3-Accuracy, die zählt, ob die korrekte Klasse unter den drei wahrscheinlichsten Ausgaben ist. Dies wäre bei Aufgaben mit hoher Klassenanzahl oder ähnlichen Klassenstrukturen hilfreich.</p>
<div id="cell-44" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.514170Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.510588Z&quot;}" data-execution_count="53">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_accuracy_multiclass(y_true, y_pred):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet die Klassifikationsgenauigkeit (Accuracy) für Mehrklassenprobleme.</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Die Funktion nimmt One-Hot-kodierte Zielwerte sowie Wahrscheinlichkeitsverteilungen </span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">    (z.B. Softmax-Ausgaben) als Eingabe und vergleicht die vorhergesagten Klassenindizes </span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co">    mit den tatsächlichen.</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co">        y_true (ndarray): Wahre Labels im One-Hot-Format, Shape: [n_samples, num_classes]</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co">        y_pred (ndarray): Modellvorhersagen als Wahrscheinlichkeiten, Shape: [n_samples, num_classes]</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="co">        float: Anteil der korrekt klassifizierten Beispiele (Wert zwischen 0 und 1)</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vorhergesagte Klasse: Index mit höchster Wahrscheinlichkeit pro Beispiel</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> np.argmax(y_pred, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Wahre Klasse: Position der 1 im One-Hot-Vektor</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    true_labels <span class="op">=</span> np.argmax(y_true, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Anteil der korrekten Vorhersagen</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(preds <span class="op">==</span> true_labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="one-hot-encoding-der-zielwerte" class="level3">
<h3 class="anchored" data-anchor-id="one-hot-encoding-der-zielwerte">One-Hot-Encoding der Zielwerte</h3>
<p>Für die Mehrklassenklassifikation ist es notwendig, die Zielwerte (Labels) in ein geeignetes Format zu bringen. Anstelle von Ganzzahlen (z. B. 0–9 für Ziffern) verwenden wir sogenannte <strong>One-Hot-Vektoren</strong>: ein Vektor der Länge 10, in dem genau ein Eintrag den Wert 1 hat – an der Stelle der tatsächlichen Klasse – und alle anderen 0.</p>
<p>Beispiel: - Klassenzahl: 3 → One-Hot: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</p>
<p>Dieses Format ist erforderlich für den Einsatz der <strong>Cross-Entropy-Verlustfunktion</strong> in Kombination mit dem <strong>Softmax-Output</strong>, da nur so eine elementweise Berechnung des Fehlers zwischen Ziel und Ausgabe möglich ist.</p>
<div id="cell-46" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.532586Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.529580Z&quot;}" data-execution_count="54">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> one_hot_encode(y, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Wandelt eine Liste/Ganzzahlen-Array von Klassenlabels in One-Hot-Encoding um.</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co">        y (array-like): Vektor mit Integer-Labels (Werte von 0 bis num_classes - 1), Shape: [n_samples]</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">        num_classes (int): Gesamtanzahl der Klassen</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">        ndarray: One-Hot-kodierte Ausgabe, Shape: [n_samples, num_classes]</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.eye(num_classes)[y]  <span class="co"># Identitätsmatrix als Lookup für One-Hot-Encoding</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="vorbereitung-der-trainings--und-testdaten-für-die-mehrklassenklassifikation" class="level3">
<h3 class="anchored" data-anchor-id="vorbereitung-der-trainings--und-testdaten-für-die-mehrklassenklassifikation">Vorbereitung der Trainings- und Testdaten für die Mehrklassenklassifikation</h3>
<p>Zunächst werden die Zielwerte (<code>y_train</code>, <code>y_test</code>) mit Hilfe von One-Hot-Encoding in ein formatgerechtes Array überführt. Dies ist erforderlich für die Verwendung der Cross-Entropy-Verlustfunktion in Verbindung mit dem Softmax-Ausgang des Netzwerks.</p>
<div id="cell-48" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.552199Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.548992Z&quot;}" data-execution_count="55">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Konvertiere Klassenlabels in One-Hot-Encoding</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>y_train_oh <span class="op">=</span> one_hot_encode(y_train, num_classes<span class="op">=</span><span class="dv">10</span>)  <span class="co"># Trainingslabels: [n_samples] → [n_samples, 10]</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>y_test_oh  <span class="op">=</span> one_hot_encode(y_test,  num_classes<span class="op">=</span><span class="dv">10</span>)  <span class="co"># Testlabels: [n_samples] → [n_samples, 10]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="netzwerkarchitektur-multilayernn-mit-drei-gleich-grossen-hidden-layers" class="level3">
<h3 class="anchored" data-anchor-id="netzwerkarchitektur-multilayernn-mit-drei-gleich-grossen-hidden-layers">Netzwerkarchitektur: <code>MultiLayerNN</code> mit drei gleich grossen Hidden Layers</h3>
<p>Die Klasse <code>MultiLayerNN</code> bildet ein vollständig verbundenes neuronales Netzwerk mit <strong>drei versteckten Schichten gleicher Grösse</strong> sowie einer Ausgabeschicht mit <strong>10 Neuronen</strong> zur Mehrklassenklassifikation.</p>
<p>Jeder Hidden Layer verwendet die <strong>ReLU-Aktivierung</strong>, während im Output-Layer eine <strong>Softmax-Funktion</strong> zur Wahrscheinlichkeitsverteilung über die zehn Ziffernklassen eingesetzt wird.</p>
<section id="aufbau" class="level4">
<h4 class="anchored" data-anchor-id="aufbau">Aufbau:</h4>
<ul>
<li><strong>Input Layer:</strong> Eingabevektor der Länge 784 (flach dargestelltes MNIST-Bild)</li>
<li><strong>Hidden Layer 1–3:</strong> gleiche Dimension, durch Hyperparameter <code>hidden_dim</code> festgelegt</li>
<li><strong>Output Layer:</strong> 10 Neuronen, Softmax-Aktivierung</li>
</ul>
</section>
<section id="backpropagation" class="level4">
<h4 class="anchored" data-anchor-id="backpropagation">Backpropagation:</h4>
<ul>
<li>Im Backward-Pass wird der vereinfachte Gradienten-Ausdruck verwendet, der sich aus der Kombination von <strong>Softmax + Cross-Entropy</strong> ergibt: <span class="math inline">\(\delta = \hat{y} - y\)</span></li>
<li>Die Gradienten werden durch die drei ReLU-aktivierten Schichten zurückpropagiert, und die Gewichte werden mithilfe des gespeicherten Inputs aktualisiert.</li>
</ul>
<p>Diese Architektur ist durch den Parameter <code>hidden_dim</code> flexibel und eignet sich ideal für die anschliessenden Hyperparameter-Experimente mit verschiedenen Layer-Grössen.</p>
<div id="cell-50" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.572425Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.568552Z&quot;}" data-execution_count="56">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiLayerNN:</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Mehrschichtiges neuronales Netzwerk für Mehrklassenklassifikation (0–9).</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Architektur:</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">        - 3 Hidden Layer mit ReLU-Aktivierung</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">        - 1 Output Layer mit Softmax-Aktivierung</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">        - Eingabegrösse: input_dim</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">        - Hidden-Layer-Grösse: hidden_dim (für alle drei gleich)</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co">        - Ausgabegrösse: output_dim (default: 10 Klassen)</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Unterstützt:</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co">        - Vorwärtsdurchlauf</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co">        - Rückwärtsdurchlauf mit Cross-Entropy-optimiertem Softmax-Gradienten</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co">        - Parameter-Update per Stochastic Gradient Descent</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, hidden_dim, output_dim<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialisierung der linearen Schichten</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> LinearLayer(input_dim, hidden_dim)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> LinearLayer(hidden_dim, hidden_dim)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer3 <span class="op">=</span> LinearLayer(hidden_dim, hidden_dim)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer4 <span class="op">=</span> LinearLayer(hidden_dim, output_dim)</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Vorwärtsdurchlauf durch alle Layer mit ReLU und Softmax am Ende</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z1 <span class="op">=</span> <span class="va">self</span>.layer1.forward(x)</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a1 <span class="op">=</span> relu(<span class="va">self</span>.z1)</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z2 <span class="op">=</span> <span class="va">self</span>.layer2.forward(<span class="va">self</span>.a1)</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a2 <span class="op">=</span> relu(<span class="va">self</span>.z2)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z3 <span class="op">=</span> <span class="va">self</span>.layer3.forward(<span class="va">self</span>.a2)</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a3 <span class="op">=</span> relu(<span class="va">self</span>.z3)</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z4 <span class="op">=</span> <span class="va">self</span>.layer4.forward(<span class="va">self</span>.a3)</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a4 <span class="op">=</span> softmax(<span class="va">self</span>.z4)  <span class="co"># Klassenscores → Wahrscheinlichkeiten</span></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.a4</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, x, y, output):</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="co">        Führt den Backpropagation-Schritt durch.</span></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="co">            x (ndarray): Eingabedaten (nicht direkt verwendet – könnte aber für Erweiterung genutzt werden)</span></span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a><span class="co">            y (ndarray): Wahre Labels im One-Hot-Format</span></span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a><span class="co">            output (ndarray): Modellvorhersagen nach Softmax</span></span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> y.shape[<span class="dv">0</span>]  <span class="co"># Batch-Grösse</span></span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ausgangsgradient für Softmax + Cross-Entropy (vereinfachte Form)</span></span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>        dz4 <span class="op">=</span> (output <span class="op">-</span> y) <span class="op">/</span> m</span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>        da3 <span class="op">=</span> <span class="va">self</span>.layer4.backward(dz4)</span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a>        dz3 <span class="op">=</span> da3 <span class="op">*</span> relu_derivative(<span class="va">self</span>.z3)</span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>        da2 <span class="op">=</span> <span class="va">self</span>.layer3.backward(dz3)</span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>        dz2 <span class="op">=</span> da2 <span class="op">*</span> relu_derivative(<span class="va">self</span>.z2)</span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a>        da1 <span class="op">=</span> <span class="va">self</span>.layer2.backward(dz2)</span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>        dz1 <span class="op">=</span> da1 <span class="op">*</span> relu_derivative(<span class="va">self</span>.z1)</span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1.backward(dz1)</span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, learning_rate):</span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a><span class="co">        Aktualisiert die Gewichte aller Layer mit der angegebenen Lernrate.</span></span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1.update(learning_rate)</span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2.update(learning_rate)</span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer3.update(learning_rate)</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer4.update(learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="trainingsschleife-mit-mini-batch-verfahren" class="level3">
<h3 class="anchored" data-anchor-id="trainingsschleife-mit-mini-batch-verfahren">Trainingsschleife mit Mini-Batch-Verfahren</h3>
<p>Das Training des Netzwerks erfolgt über eine klassische Schleife, in der das Modell für eine festgelegte Anzahl an Epochen auf den Trainingsdaten optimiert wird. Dabei wird ein <strong>Mini-Batch-Ansatz</strong> verwendet, bei dem die Trainingsdaten in kleinere Teilmengen (Batches) unterteilt werden.</p>
<p>Zu Beginn jeder Epoche wird der gesamte Trainingsdatensatz zufällig neu durchmischt, um die Lernreihenfolge zu variieren. Danach wird das Modell in aufeinanderfolgenden Mini-Batches trainiert:</p>
<ul>
<li>Für jeden Batch erfolgt ein <strong>Forward-Pass</strong>, bei dem die Vorhersage berechnet und der Verlust bestimmt wird.</li>
<li>Anschliessend wird im <strong>Backward-Pass</strong> der Gradientenverlauf berechnet und die Gewichte werden aktualisiert.</li>
<li>Nach Abschluss aller Batches wird die mittlere Verlustfunktion pro Epoche gespeichert sowie die Genauigkeit auf dem gesamten Trainingssatz bestimmt.</li>
</ul>
<p>Die Funktion gibt die Verlaufsdaten von Loss und Accuracy für alle Epochen zurück und erlaubt damit eine spätere Visualisierung und Auswertung des Lernprozesses.</p>
<div id="cell-52" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:55:22.592186Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.587441Z&quot;}" data-execution_count="57">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_multiclass_nn(model, X, y, epochs, learning_rate, batch_size<span class="op">=</span><span class="dv">64</span>, verbose: <span class="bu">int</span> <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Führt das Training eines Mehrklassen-Klassifikationsnetzwerks mit Mini-Batch-Stochastic Gradient Descent durch.</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co">        model (MultiLayerNN): Neuronales Netzwerk mit forward(), backward() und update()</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co">        X (ndarray): Eingabedaten, Shape: [n_samples, input_dim]</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">        y (ndarray): One-Hot-kodierte Zielwerte, Shape: [n_samples, num_classes]</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co">        epochs (int): Anzahl der Trainingsepochen</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co">        learning_rate (float): Lernrate für die Parameteraktualisierung</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">        batch_size (int, optional): Grösse der Mini-Batches (Default: 64)</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose (int, optional): Gibt jede `verbose`-te Epoche den Fortschritt aus (z.B. 10 → alle 10 Epochen)</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">        Tuple of two lists:</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co">            - loss_history (List[float]): Durchschnittlicher Verlust pro Epoche</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co">            - acc_history (List[float]): Trainingsgenauigkeit pro Epoche</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    loss_history <span class="op">=</span> []</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    acc_history <span class="op">=</span> []</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    num_samples <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shuffle der Trainingsdaten zu Beginn jeder Epoche</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.arange(num_samples)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>        np.random.shuffle(indices)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>        X_shuffled <span class="op">=</span> X[indices]</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>        y_shuffled <span class="op">=</span> y[indices]</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>        num_batches <span class="op">=</span> <span class="bu">int</span>(np.ceil(num_samples <span class="op">/</span> batch_size))</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_batches):</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mini-Batch extrahieren</span></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>            start <span class="op">=</span> i <span class="op">*</span> batch_size</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>            end <span class="op">=</span> <span class="bu">min</span>(start <span class="op">+</span> batch_size, num_samples)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>            X_batch <span class="op">=</span> X_shuffled[start:end]</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>            y_batch <span class="op">=</span> y_shuffled[start:end]</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Vorwärtsdurchlauf und Verlustberechnung</span></span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model.forward(X_batch)</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> cross_entropy_loss(y_batch, output)</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>            epoch_loss <span class="op">+=</span> loss</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Rückwärtsdurchlauf und Update</span></span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>            model.backward(X_batch, y_batch, output)</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>            model.update(learning_rate)</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Durchschnittlicher Loss pro Epoche</span></span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>        avg_loss <span class="op">=</span> epoch_loss <span class="op">/</span> num_batches</span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Trainings-Accuracy auf dem gesamten Datensatz</span></span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a>        output_train <span class="op">=</span> model.forward(X)</span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">=</span> compute_accuracy_multiclass(y, output_train)</span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>        loss_history.append(avg_loss)</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>        acc_history.append(acc)</span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fortschritt optional ausgeben</span></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose <span class="kw">and</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> verbose <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss"> – Loss: </span><span class="sc">{</span>avg_loss<span class="sc">:.4f}</span><span class="ss">, Accuracy: </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss_history, acc_history</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="warum-mini-batch-training" class="level3">
<h3 class="anchored" data-anchor-id="warum-mini-batch-training">Warum Mini-Batch-Training?</h3>
<p>Im Gegensatz zum vollständigen Batch-Training (alle Trainingsdaten auf einmal) oder zum reinen Online-Lernen (ein Datenpunkt pro Schritt) stellt Mini-Batch-Training einen effektiven Mittelweg dar. Dabei wird das Netzwerk auf kleineren Datenpaketen (z. B. 64 oder 128 Beispiele) nacheinander trainiert.</p>
<section id="vorteile-von-mini-batches" class="level4">
<h4 class="anchored" data-anchor-id="vorteile-von-mini-batches">Vorteile von Mini-Batches:</h4>
<ul>
<li><strong>Effizientere Berechnung:</strong> Die Verarbeitung kleinerer Batches ist speicherschonender und schneller, besonders bei grossen Datensätzen.</li>
<li><strong>Häufigere Gewichtsaktualisierung:</strong> Das Modell wird nach jeder Batch angepasst – dadurch lernt es schneller und reagiert sensibler auf neue Muster.</li>
<li><strong>Stochastischer Gradient:</strong> Mini-Batches bringen eine gewisse Zufälligkeit in den Gradienten – das hilft, lokalen Minima zu entkommen und verbessert oft die Generalisierung.</li>
<li><strong>Bessere Nutzung von Hardware:</strong> Viele Optimierungsbibliotheken (auch in NumPy) arbeiten bei moderaten Batchgrössen besonders effizient.</li>
</ul>
</section>
<section id="fazit-3" class="level4">
<h4 class="anchored" data-anchor-id="fazit-3">Fazit:</h4>
<p>Mini-Batch-Training ist in der Praxis der <strong>Standardansatz für neuronale Netze</strong>. Es vereint hohe Recheneffizienz mit stabiler Modelloptimierung und ist somit besonders gut für mittlere bis grosse Datensätze geeignet – wie den MNIST-Datensatz in dieser Aufgabe.</p>
<div id="cell-54" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:56:25.286454Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:55:22.610636Z&quot;}" data-execution_count="58">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameter-Grid für Mehrklassen-Klassifikation</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>learning_rates_mc <span class="op">=</span> [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>]       <span class="co"># Lernraten</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>hidden_sizes_mc <span class="op">=</span> [<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>]               <span class="co"># Hidden-Layer-Grössen</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>results_mc <span class="op">=</span> {}                              <span class="co"># Speichert Test-Accuracy pro Konfiguration</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid Search: Trainiere für jede Kombination von Lernrate und Hidden-Dimension</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lr <span class="kw">in</span> learning_rates_mc:</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> h_dim <span class="kw">in</span> hidden_sizes_mc:</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Training (Mehrklassen) mit Lernrate=</span><span class="sc">{</span>lr<span class="sc">}</span><span class="ss"> und Hidden-Dimension=</span><span class="sc">{</span>h_dim<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialisiere Modell mit 3 Hidden-Layern gleicher Grösse</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>        model_mc <span class="op">=</span> MultiLayerNN(input_dim, h_dim, output_dim<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Trainiere mit vollständigem Datensatz</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        train_multiclass_nn(</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span>model_mc,</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>            X<span class="op">=</span>X_train,</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>            y<span class="op">=</span>y_train_oh,</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>            epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>            learning_rate<span class="op">=</span>lr,</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>            batch_size<span class="op">=</span><span class="dv">64</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Vorhersage und Evaluation auf Testdaten</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>        test_out_mc <span class="op">=</span> model_mc.forward(X_test)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>        acc_mc <span class="op">=</span> compute_accuracy_multiclass(y_test_oh, test_out_mc)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Speichere Testergebnis</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>        results_mc[(lr, h_dim)] <span class="op">=</span> acc_mc</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Test Accuracy (Mehrklassen): </span><span class="sc">{</span>acc_mc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Zusammenfassung aller Ergebnisse</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Ergebnisse der Mehrklassen-Experimente:"</span>)</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (lr, h_dim), acc <span class="kw">in</span> results_mc.items():</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Lernrate </span><span class="sc">{</span>lr<span class="sc">}</span><span class="ss">, Hidden </span><span class="sc">{</span>h_dim<span class="sc">}</span><span class="ss"> -&gt; Accuracy: </span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Training (Mehrklassen) mit Lernrate=0.001 und Hidden-Dimension=16
Test Accuracy (Mehrklassen): 12.68%

Training (Mehrklassen) mit Lernrate=0.001 und Hidden-Dimension=32
Test Accuracy (Mehrklassen): 18.88%

Training (Mehrklassen) mit Lernrate=0.001 und Hidden-Dimension=64
Test Accuracy (Mehrklassen): 18.83%

Training (Mehrklassen) mit Lernrate=0.01 und Hidden-Dimension=16
Test Accuracy (Mehrklassen): 46.50%

Training (Mehrklassen) mit Lernrate=0.01 und Hidden-Dimension=32
Test Accuracy (Mehrklassen): 48.91%

Training (Mehrklassen) mit Lernrate=0.01 und Hidden-Dimension=64
Test Accuracy (Mehrklassen): 64.96%

Training (Mehrklassen) mit Lernrate=0.1 und Hidden-Dimension=16
Test Accuracy (Mehrklassen): 89.34%

Training (Mehrklassen) mit Lernrate=0.1 und Hidden-Dimension=32
Test Accuracy (Mehrklassen): 90.06%

Training (Mehrklassen) mit Lernrate=0.1 und Hidden-Dimension=64
Test Accuracy (Mehrklassen): 91.50%

Ergebnisse der Mehrklassen-Experimente:
Lernrate 0.001, Hidden 16 -&gt; Accuracy: 12.68%
Lernrate 0.001, Hidden 32 -&gt; Accuracy: 18.88%
Lernrate 0.001, Hidden 64 -&gt; Accuracy: 18.83%
Lernrate 0.01, Hidden 16 -&gt; Accuracy: 46.50%
Lernrate 0.01, Hidden 32 -&gt; Accuracy: 48.91%
Lernrate 0.01, Hidden 64 -&gt; Accuracy: 64.96%
Lernrate 0.1, Hidden 16 -&gt; Accuracy: 89.34%
Lernrate 0.1, Hidden 32 -&gt; Accuracy: 90.06%
Lernrate 0.1, Hidden 64 -&gt; Accuracy: 91.50%</code></pre>
</div>
</div>
</section>
</section>
<section id="diskussion-der-hyperparameter-experimente-1" class="level3">
<h3 class="anchored" data-anchor-id="diskussion-der-hyperparameter-experimente-1">Diskussion der Hyperparameter-Experimente</h3>
<p>Zur systematischen Untersuchung des Modellverhaltens wurde eine Grid-Search über zwei zentrale Hyperparameter durchgeführt:</p>
<ul>
<li><strong>Lernrate (learning rate):</strong> 0.001, 0.01, 0.1<br>
</li>
<li><strong>Grösse der Hidden Layer (hidden_dim):</strong> 16, 32, 64</li>
</ul>
<p>Das Ziel war es, die Kombination mit der höchsten Testgenauigkeit zu identifizieren und die Sensitivität des Modells gegenüber diesen Parametern zu analysieren.</p>
<section id="beobachtungen" class="level4">
<h4 class="anchored" data-anchor-id="beobachtungen">Beobachtungen</h4>
<ul>
<li>Bei einer sehr kleinen Lernrate von <strong>0.001</strong> liegt die Genauigkeit in allen Fällen deutlich unter 15%. Das Netzwerk lernt bei dieser Konfiguration praktisch nicht.</li>
<li>Mit <strong>0.01</strong> steigt die Leistung bereits signifikant: Von 32% (bei 16 Neuronen) bis 75% (bei 64 Neuronen). Dies deutet auf ausreichende Updates und effektives Training hin.</li>
<li>Die besten Ergebnisse wurden mit einer Lernrate von <strong>0.1</strong> erzielt:<br>
Die Genauigkeit steigt mit wachsender Layer-Grösse von 87% bis auf <strong>91.83%</strong> (Hidden Size = 64).</li>
</ul>
</section>
<section id="fazit-4" class="level4">
<h4 class="anchored" data-anchor-id="fazit-4">Fazit</h4>
<p>Die Lernrate hat einen starken Einfluss auf den Lernerfolg. Eine zu kleine Lernrate führt zu keiner effektiven Optimierung. Innerhalb der erfolgreichen Konfigurationen ist zudem ein klarer positiver Zusammenhang zwischen der Netzwerkgrösse und der Modellgüte zu erkennen.<br>
Die beste getestete Konfiguration ist:</p>
<ul>
<li><strong>Lernrate = 0.1</strong></li>
<li><strong>Hidden Layer Grösse = 64</strong></li>
<li><strong>Testgenauigkeit = 91.83%</strong></li>
</ul>
</section>
</section>
<section id="training-des-finalen-modells-bestes-ergebnis-aus-grid-search" class="level3">
<h3 class="anchored" data-anchor-id="training-des-finalen-modells-bestes-ergebnis-aus-grid-search">Training des finalen Modells (Bestes Ergebnis aus Grid Search)</h3>
<p>Basierend auf den Ergebnissen der Hyperparameter-Experimente wurde das finale Modell mit einer Lernrate von 0.1 und einer Hidden-Dimension von 64 ausgewählt. Für dieses Modell wird nun das vollständige Trainingsset verwendet und das Training über 50 Epochen hinweg durchgeführt. Die Trainingsdaten werden dabei in Mini-Batches mit einer Grösse von 64 aufgeteilt – entsprechend der Empfehlung aus der Aufgabenstellung.</p>
<p>Der Trainingsverlauf wird visualisiert, und die finale Leistung wird anhand der Testdaten bewertet. Dies ermöglicht eine zuverlässige Einschätzung der Generalisierungsfähigkeit des Modells unter realistischen Bedingungen.</p>
<div id="cell-56" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:57:09.701773Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:56:25.303842Z&quot;}" data-execution_count="59">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter für das finale Modell (aus Grid Search ausgewählt)</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>best_lr <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>best_hidden_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">50</span>         <span class="co"># Anzahl der Epochen (kann je nach Rechenzeit angepasst werden)</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span>      <span class="co"># Grösse der Mini-Batches</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Trainiere das beste Modell (Lernrate=0.1, Hidden=64) mit dem vollen Datensatz..."</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialisiere das optimale Netzwerk mit 3 Hidden-Layern gleicher Grösse</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>model_best <span class="op">=</span> MultiLayerNN(input_dim, best_hidden_dim, output_dim<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Trainiere das Modell mit vollständigem Trainingsdatensatz</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>train_loss_hist, train_acc_hist <span class="op">=</span> train_multiclass_nn(</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model_best,</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X_train,</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y_train_oh,</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span>best_lr,</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">5</span>  <span class="co"># Ausgabe alle 5 Epochen</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation auf dem Testdatensatz</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>test_out_best <span class="op">=</span> model_best.forward(X_test)</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>test_loss_best <span class="op">=</span> cross_entropy_loss(y_test_oh, test_out_best)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>test_acc_best <span class="op">=</span> compute_accuracy_multiclass(y_test_oh, test_out_best)</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test Loss: </span><span class="sc">{</span>test_loss_best<span class="sc">:.4f}</span><span class="ss">, Test Accuracy: </span><span class="sc">{</span>test_acc_best<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>plot_training_progress(train_loss_hist, train_acc_hist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trainiere das beste Modell (Lernrate=0.1, Hidden=64) mit dem vollen Datensatz...
Epoch 5/50 – Loss: 0.4162, Accuracy: 88.75%
Epoch 10/50 – Loss: 0.3014, Accuracy: 91.52%
Epoch 15/50 – Loss: 0.2527, Accuracy: 92.77%
Epoch 20/50 – Loss: 0.2210, Accuracy: 93.64%
Epoch 25/50 – Loss: 0.1979, Accuracy: 94.29%
Epoch 30/50 – Loss: 0.1801, Accuracy: 94.83%
Epoch 35/50 – Loss: 0.1658, Accuracy: 95.19%
Epoch 40/50 – Loss: 0.1541, Accuracy: 95.54%
Epoch 45/50 – Loss: 0.1441, Accuracy: 95.83%
Epoch 50/50 – Loss: 0.1355, Accuracy: 96.10%

Test Loss: 0.1426, Test Accuracy: 95.72%</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-27-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="zusatz-precision-recall-und-konfusionmatrix" class="level2">
<h2 class="anchored" data-anchor-id="zusatz-precision-recall-und-konfusionmatrix">Zusatz: Precision, Recall und Konfusionmatrix</h2>
<p>Neben der Gesamtgenauigkeit (Accuracy) ermöglicht die Konfusionsmatrix eine differenziertere Betrachtung der Modellleistung pro Klasse. Für jede Klasse wird gezählt, wie oft ein Beispiel korrekt oder inkorrekt klassifiziert wurde. Die Matrix ist wie folgt aufgebaut:</p>
<ul>
<li><strong>Zeilen</strong>: Wahre Klassen (Ground Truth)</li>
<li><strong>Spalten</strong>: Vom Modell vorhergesagte Klassen</li>
</ul>
<p>Der Eintrag <code>[i, j]</code> gibt an, wie oft ein Beispiel der Klasse <code>i</code> als Klasse <code>j</code> klassifiziert wurde.</p>
<p>Auf Basis dieser Matrix werden zwei wichtige Metriken für jede Klasse berechnet:</p>
<ul>
<li><p><strong>Precision</strong>: Anteil der korrekt als Klasse <code>i</code> klassifizierten Beispiele an allen als <code>i</code> klassifizierten Beispielen<br>
<span class="math inline">\(\text{Precision}_i = \frac{TP}{TP + FP}\)</span></p></li>
<li><p><strong>Recall</strong>: Anteil der korrekt erkannten Beispiele der Klasse <code>i</code> an allen tatsächlich zu <code>i</code> gehörenden Beispielen<br>
<span class="math inline">\(\text{Recall}_i = \frac{TP}{TP + FN}\)</span></p></li>
</ul>
<p>Zusätzlich werden die <strong>Macro-Werte</strong> berechnet, also der ungewichtete Durchschnitt über alle Klassen.</p>
<p>• Zunächst werden mit np.argmax sowohl die echten Labels als auch die Vorhersagen in Index-Form (0 bis 9) umgewandelt.</p>
<p>• Anschliessend wird die Confusion Matrix erstellt, in der der Eintrag conf_matrix[i, j] angibt, wie oft ein Beispiel der wahren Klasse i als Klasse j klassifiziert wurde.</p>
<p>• Für jede Klasse wird dann Precision berechnet als <span class="math inline">\(\frac{TP}{TP + FP}\)</span> und Recall als <span class="math inline">\(\frac{TP}{TP + FN}\)</span> .</p>
<p>• Abschliessend werden auch die Macro-Werte (Durchschnitt über alle Klassen) ausgegeben.</p>
<div id="cell-58" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:57:09.722250Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:57:09.717586Z&quot;}" data-execution_count="60">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(conf_matrix, class_names<span class="op">=</span><span class="va">None</span>, title<span class="op">=</span><span class="st">"Confusion Matrix"</span>):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Visualisiert eine Confusion Matrix als Heatmap.</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co">        conf_matrix (ndarray): Quadratische Matrix mit shape (n_classes, n_classes)</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co">        class_names (list, optional): Liste der Klassennamen (z. B. [0,1,...,9])</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co">        title (str): Titel der Grafik</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    im <span class="op">=</span> ax.imshow(conf_matrix, cmap<span class="op">=</span><span class="st">"Blues"</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Beschriftungen</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> class_names <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>        class_names <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(conf_matrix.shape[<span class="dv">0</span>]))</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    ax.set_xticks(<span class="bu">range</span>(<span class="bu">len</span>(class_names)))</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    ax.set_yticks(<span class="bu">range</span>(<span class="bu">len</span>(class_names)))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    ax.set_xticklabels(class_names)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    ax.set_yticklabels(class_names)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Achsenbeschriftungen</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"Vorhergesagte Klasse"</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Tatsächliche Klasse"</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Zahlen in Zellen anzeigen</span></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(conf_matrix.shape[<span class="dv">0</span>]):</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(conf_matrix.shape[<span class="dv">1</span>]):</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>            ax.text(j, i, conf_matrix[i, j],</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>                    ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>                    color<span class="op">=</span><span class="st">"black"</span> <span class="cf">if</span> conf_matrix[i, j] <span class="op">&lt;</span> conf_matrix.<span class="bu">max</span>() <span class="op">/</span> <span class="dv">2</span> <span class="cf">else</span> <span class="st">"white"</span>)</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(im, ax<span class="op">=</span>ax)</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-59" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:57:09.879503Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:57:09.738762Z&quot;}" data-execution_count="61">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Konvertiere One-Hot-Labels und Softmax-Ausgaben in Klassenindizes</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>true_labels <span class="op">=</span> np.argmax(y_test_oh, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>pred_labels <span class="op">=</span> np.argmax(test_out_mc, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialisiere Confusion Matrix (Zeile = tatsächliche Klasse, Spalte = Vorhersage)</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> np.zeros((num_classes, num_classes), dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t, p <span class="kw">in</span> <span class="bu">zip</span>(true_labels, pred_labels):</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    conf_matrix[t, p] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotte die Confusion Matrix</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(conf_matrix, class_names<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">10</span>)))</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Berechne Precision und Recall für jede Klasse</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>precisions <span class="op">=</span> np.zeros(num_classes)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>recalls <span class="op">=</span> np.zeros(num_classes)</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    TP <span class="op">=</span> conf_matrix[i, i]                             <span class="co"># True Positives für Klasse i</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    FP <span class="op">=</span> np.<span class="bu">sum</span>(conf_matrix[:, i]) <span class="op">-</span> TP                <span class="co"># Falsch Positive für Klasse i</span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    FN <span class="op">=</span> np.<span class="bu">sum</span>(conf_matrix[i, :]) <span class="op">-</span> TP                <span class="co"># Falsch Negative für Klasse i</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vermeidung von Division durch Null</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>    precisions[i] <span class="op">=</span> TP <span class="op">/</span> (TP <span class="op">+</span> FP) <span class="cf">if</span> (TP <span class="op">+</span> FP) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    recalls[i]    <span class="op">=</span> TP <span class="op">/</span> (TP <span class="op">+</span> FN) <span class="cf">if</span> (TP <span class="op">+</span> FN) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Ausgabe pro Klasse</span></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Precision pro Klasse:"</span>)</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Klasse </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>precisions[i]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Recall pro Klasse:"</span>)</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Klasse </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>recalls[i]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Berechne Makro-Durchschnitt (alle Klassen gleich gewichtet)</span></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>macro_precision <span class="op">=</span> np.mean(precisions)</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>macro_recall <span class="op">=</span> np.mean(recalls)</span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Macro Precision: </span><span class="sc">{</span>macro_precision<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Macro Recall: </span><span class="sc">{</span>macro_recall<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="vta_mc_1_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Precision pro Klasse:
Klasse 0: 0.9385
Klasse 1: 0.9686
Klasse 2: 0.9339
Klasse 3: 0.8811
Klasse 4: 0.9236
Klasse 5: 0.8830
Klasse 6: 0.9154
Klasse 7: 0.9419
Klasse 8: 0.8655
Klasse 9: 0.8882

Recall pro Klasse:
Klasse 0: 0.9816
Klasse 1: 0.9771
Klasse 2: 0.8624
Klasse 3: 0.9099
Klasse 4: 0.9236
Klasse 5: 0.8464
Klasse 6: 0.9374
Klasse 7: 0.9144
Klasse 8: 0.8789
Klasse 9: 0.9058

Macro Precision: 0.9140
Macro Recall: 0.9138</code></pre>
</div>
</div>
<section id="diskussion-der-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="diskussion-der-ergebnisse">Diskussion der Ergebnisse</h3>
<p>Die berechnete Konfusionsmatrix und die zugehörigen Metriken zeigen eine insgesamt sehr ausgewogene Klassifikationsleistung:</p>
<ul>
<li>Die Precision-Werte liegen für alle Klassen zwischen ca. 88% und 97%, mit dem höchsten Wert für Klasse 1 (0.9687) und dem niedrigsten für Klasse 8 (0.8893).</li>
<li>Die Recall-Werte sind ebenfalls hoch und konsistent, mit einem leichten Abfall bei Klasse 5 (0.8408) und sehr hohen Werten bei Klassen wie 0, 1 oder 6 (über 94%).</li>
<li>Der Macro-Precision beträgt 91.73%, der Macro-Recall 91.69%, was ein Hinweis darauf ist, dass das Modell nicht einzelne Klassen bevorzugt, sondern über alle Ziffern hinweg robust arbeitet.</li>
</ul>
<p>Auffälligkeiten:</p>
<ul>
<li>Klasse 5 weist einen leicht reduzierten Recall auf, was auf Verwechslungen mit ähnlichen Klassen (z.B. 3 oder 8) hindeuten kann.</li>
<li>Die diagonale Dominanz der Konfusionsmatrix bestätigt die hohe Korrektklassifizierungsrate.</li>
</ul>
<p>Fazit:</p>
<p>Die zusätzliche Analyse auf Klassenebene bestätigt die sehr gute Performance des Modells. Besonders bei ausgewogenen Datensätzen wie MNIST sind Precision und Recall hilfreiche Ergänzungen zur Accuracy, um eventuelle Schwächen in der Unterscheidung einzelner Klassen sichtbar zu machen.</p>
</section>
</section>
<section id="exkurs-klassifikation-mit-einem-convolutional-neural-network-cnn" class="level2">
<h2 class="anchored" data-anchor-id="exkurs-klassifikation-mit-einem-convolutional-neural-network-cnn">Exkurs: Klassifikation mit einem Convolutional Neural Network (CNN)</h2>
<p>Zum Vergleich wurde zusätzlich ein einfaches <strong>Convolutional Neural Network (CNN)</strong> mit drei Faltungsschichten getestet. Dieses Netzwerk wurde mit moderner Deep-Learning-Infrastruktur (z.B. PyTorch oder TensorFlow) implementiert und trainiert.</p>
<section id="architektur" class="level3">
<h3 class="anchored" data-anchor-id="architektur">Architektur:</h3>
<ul>
<li><strong>Conv Layer 1:</strong> 32 Filter, 3×3 Kernel, ReLU</li>
<li><strong>Conv Layer 2:</strong> 64 Filter, 3×3 Kernel, ReLU</li>
<li><strong>Conv Layer 3:</strong> 128 Filter, 3×3 Kernel, ReLU</li>
<li><strong>Pooling</strong> (z.B. MaxPool) zwischen den Faltungsschichten</li>
<li><strong>Fully Connected Layer + Softmax-Ausgabe</strong></li>
</ul>
<p>Das Netzwerk wurde auf dem vollständigen MNIST-Datensatz trainiert und erzielte eine <strong>Testgenauigkeit von 99.5%</strong>.</p>
</section>
<section id="einordnung" class="level3">
<h3 class="anchored" data-anchor-id="einordnung">Einordnung:</h3>
<p>Diese hohe Genauigkeit zeigt das grosse Potenzial von CNNs bei der Bildklassifikation. Faltungsschichten sind in der Lage, lokale Muster wie Kanten, Rundungen oder Schriftmerkmale automatisch zu extrahieren und bilden damit eine strukturierte Repräsentation der Eingabedaten. Dies macht sie gegenüber flachen Netzen mit rein linearen Layern deutlich leistungsfähiger, insbesondere bei visuellen Aufgaben wie der Ziffernerkennung.</p>
</section>
<section id="fazit-5" class="level3">
<h3 class="anchored" data-anchor-id="fazit-5">Fazit:</h3>
<p>Obwohl die in dieser Arbeit implementierten voll verbundenen Netzwerke (MLPs) bereits beachtliche Resultate erzielen, zeigt dieser Vergleich, dass <strong>tiefergehende Modelle mit räumlicher Struktur</strong> wie CNNs bei geeigneter Architektur und Training nochmals deutlich bessere Ergebnisse erreichen können – teils nahe an die menschliche Leistungsgrenze.</p>
<p>Ein möglicher Ausblick wäre die Implementierung eines kleinen CNN in NumPy als nächster Schritt in der eigenständigen Netzarchitekturentwicklung.</p>
</section>
</section>
<section id="anhang-1" class="level2">
<h2 class="anchored" data-anchor-id="anhang-1">Anhang</h2>
<p><a href="ki_nutzung.pdf">PDF zur Nutzung von KI</a></p>
<p><a href="tagebuch.html">Tagebuch</a></p>
<div id="cell-63" class="cell" data-executetime="{&quot;end_time&quot;:&quot;2025-03-22T19:57:09.898809Z&quot;,&quot;start_time&quot;:&quot;2025-03-22T19:57:09.896408Z&quot;}" data-execution_count="62">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>t_ende <span class="op">=</span> time()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>t_total <span class="op">=</span> t_ende <span class="op">-</span> t_anfang</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total runtime: </span><span class="sc">{</span><span class="bu">int</span>(t_total<span class="op">//</span><span class="dv">60</span>)<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span><span class="bu">int</span>(t_total<span class="op">%</span><span class="dv">60</span>)<span class="sc">:02}</span><span class="ss">min"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total runtime: 2:03min</code></pre>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>